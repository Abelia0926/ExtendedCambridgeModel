       # Copyright 2009 Brian Quinlan. All Rights Reserved.
       # Licensed to PSF under a Contributor Agreement.
       
    1: """Implements ThreadPoolExecutor."""
       
    1: __author__ = 'Brian Quinlan (brian@sweetapp.com)'
       
    1: from concurrent.futures import _base
    1: import itertools
    1: import queue
    1: import threading
    1: import types
    1: import weakref
    1: import os
       
       
    1: _threads_queues = weakref.WeakKeyDictionary()
    1: _shutdown = False
       # Lock that ensures that new workers are not created while the interpreter is
       # shutting down. Must be held while mutating _threads_queues and _shutdown.
    1: _global_shutdown_lock = threading.Lock()
       
    1: def _python_exit():
           global _shutdown
           with _global_shutdown_lock:
               _shutdown = True
           items = list(_threads_queues.items())
           for t, q in items:
               q.put(None)
           for t, q in items:
               t.join()
       
       # Register for `_python_exit()` to be called just before joining all
       # non-daemon threads. This is used instead of `atexit.register()` for
       # compatibility with subinterpreters, which no longer support daemon threads.
       # See bpo-39812 for context.
    1: threading._register_atexit(_python_exit)
       
       # At fork, reinitialize the `_global_shutdown_lock` lock in the child process
    1: if hasattr(os, 'register_at_fork'):
    2:     os.register_at_fork(before=_global_shutdown_lock.acquire,
    1:                         after_in_child=_global_shutdown_lock._at_fork_reinit,
    1:                         after_in_parent=_global_shutdown_lock.release)
       
       
    2: class _WorkItem(object):
    1:     def __init__(self, future, fn, args, kwargs):
               self.future = future
               self.fn = fn
               self.args = args
               self.kwargs = kwargs
       
    1:     def run(self):
               if not self.future.set_running_or_notify_cancel():
                   return
       
               try:
                   result = self.fn(*self.args, **self.kwargs)
               except BaseException as exc:
                   self.future.set_exception(exc)
                   # Break a reference cycle with the exception 'exc'
                   self = None
               else:
                   self.future.set_result(result)
       
    1:     __class_getitem__ = classmethod(types.GenericAlias)
       
       
    1: def _worker(executor_reference, work_queue, initializer, initargs):
           if initializer is not None:
               try:
                   initializer(*initargs)
               except BaseException:
                   _base.LOGGER.critical('Exception in initializer:', exc_info=True)
                   executor = executor_reference()
                   if executor is not None:
                       executor._initializer_failed()
                   return
           try:
               while True:
                   work_item = work_queue.get(block=True)
                   if work_item is not None:
                       work_item.run()
                       # Delete references to object. See issue16284
                       del work_item
       
                       # attempt to increment idle count
                       executor = executor_reference()
                       if executor is not None:
                           executor._idle_semaphore.release()
                       del executor
                       continue
       
                   executor = executor_reference()
                   # Exit if:
                   #   - The interpreter is shutting down OR
                   #   - The executor that owns the worker has been collected OR
                   #   - The executor that owns the worker has been shutdown.
                   if _shutdown or executor is None or executor._shutdown:
                       # Flag the executor as shutting down as early as possible if it
                       # is not gc-ed yet.
                       if executor is not None:
                           executor._shutdown = True
                       # Notice other workers
                       work_queue.put(None)
                       return
                   del executor
           except BaseException:
               _base.LOGGER.critical('Exception in worker', exc_info=True)
       
       
    2: class BrokenThreadPool(_base.BrokenExecutor):
    1:     """
           Raised when a worker thread in a ThreadPoolExecutor failed initializing.
           """
       
       
    2: class ThreadPoolExecutor(_base.Executor):
       
           # Used to assign unique thread names when thread_name_prefix is not supplied.
    1:     _counter = itertools.count().__next__
       
    2:     def __init__(self, max_workers=None, thread_name_prefix='',
    1:                  initializer=None, initargs=()):
               """Initializes a new ThreadPoolExecutor instance.
       
               Args:
                   max_workers: The maximum number of threads that can be used to
                       execute the given calls.
                   thread_name_prefix: An optional name prefix to give our threads.
                   initializer: A callable used to initialize worker threads.
                   initargs: A tuple of arguments to pass to the initializer.
               """
    1:         if max_workers is None:
                   # ThreadPoolExecutor is often used to:
                   # * CPU bound task which releases GIL
                   # * I/O bound task (which releases GIL, of course)
                   #
                   # We use cpu_count + 4 for both types of tasks.
                   # But we limit it to 32 to avoid consuming surprisingly large resource
                   # on many core machine.
                   max_workers = min(32, (os.cpu_count() or 1) + 4)
    1:         if max_workers <= 0:
                   raise ValueError("max_workers must be greater than 0")
       
    1:         if initializer is not None and not callable(initializer):
                   raise TypeError("initializer must be a callable")
       
    1:         self._max_workers = max_workers
    1:         self._work_queue = queue.SimpleQueue()
    1:         self._idle_semaphore = threading.Semaphore(0)
    1:         self._threads = set()
    1:         self._broken = False
    1:         self._shutdown = False
    1:         self._shutdown_lock = threading.Lock()
    2:         self._thread_name_prefix = (thread_name_prefix or
    1:                                     ("ThreadPoolExecutor-%d" % self._counter()))
    1:         self._initializer = initializer
    1:         self._initargs = initargs
       
    1:     def submit(self, fn, /, *args, **kwargs):
               with self._shutdown_lock, _global_shutdown_lock:
                   if self._broken:
                       raise BrokenThreadPool(self._broken)
       
                   if self._shutdown:
                       raise RuntimeError('cannot schedule new futures after shutdown')
                   if _shutdown:
                       raise RuntimeError('cannot schedule new futures after '
                                          'interpreter shutdown')
       
                   f = _base.Future()
                   w = _WorkItem(f, fn, args, kwargs)
       
                   self._work_queue.put(w)
                   self._adjust_thread_count()
                   return f
    1:     submit.__doc__ = _base.Executor.submit.__doc__
       
    1:     def _adjust_thread_count(self):
               # if idle threads are available, don't spin new threads
               if self._idle_semaphore.acquire(timeout=0):
                   return
       
               # When the executor gets lost, the weakref callback will wake up
               # the worker threads.
               def weakref_cb(_, q=self._work_queue):
                   q.put(None)
       
               num_threads = len(self._threads)
               if num_threads < self._max_workers:
                   thread_name = '%s_%d' % (self._thread_name_prefix or self,
                                            num_threads)
                   t = threading.Thread(name=thread_name, target=_worker,
                                        args=(weakref.ref(self, weakref_cb),
                                              self._work_queue,
                                              self._initializer,
                                              self._initargs))
                   t.start()
                   self._threads.add(t)
                   _threads_queues[t] = self._work_queue
       
    1:     def _initializer_failed(self):
               with self._shutdown_lock:
                   self._broken = ('A thread initializer failed, the thread pool '
                                   'is not usable anymore')
                   # Drain work queue and mark pending futures failed
                   while True:
                       try:
                           work_item = self._work_queue.get_nowait()
                       except queue.Empty:
                           break
                       if work_item is not None:
                           work_item.future.set_exception(BrokenThreadPool(self._broken))
       
    1:     def shutdown(self, wait=True, *, cancel_futures=False):
               with self._shutdown_lock:
                   self._shutdown = True
                   if cancel_futures:
                       # Drain all work items from the queue, and then cancel their
                       # associated futures.
                       while True:
                           try:
                               work_item = self._work_queue.get_nowait()
                           except queue.Empty:
                               break
                           if work_item is not None:
                               work_item.future.cancel()
       
                   # Send a wake-up to prevent threads calling
                   # _work_queue.get(block=True) from permanently blocking.
                   self._work_queue.put(None)
               if wait:
                   for t in self._threads:
                       t.join()
    1:     shutdown.__doc__ = _base.Executor.shutdown.__doc__
