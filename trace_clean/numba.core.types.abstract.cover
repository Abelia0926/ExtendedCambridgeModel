    1: from abc import ABCMeta, abstractmethod, abstractproperty
    1: from typing import Dict as ptDict, Type as ptType
    1: import itertools
    1: import weakref
    1: from functools import cached_property
       
    1: import numpy as np
       
    1: from numba.core.utils import get_hashable_key
       
       # Types are added to a global registry (_typecache) in order to assign
       # them unique integer codes for fast matching in _dispatcher.c.
       # However, we also want types to be disposable, therefore we ensure
       # each type is interned as a weak reference, so that it lives only as
       # long as necessary to keep a stable type code.
       # NOTE: some types can still be made immortal elsewhere (for example
       # in _dispatcher.c's internal caches).
    1: _typecodes = itertools.count()
       
    1: def _autoincr():
 2166:     n = next(_typecodes)
           # 4 billion types should be enough, right?
 2166:     assert n < 2 ** 32, "Limited to 4 billion types"
 2166:     return n
       
    1: _typecache: ptDict[weakref.ref, weakref.ref] = {}
       
    1: def _on_type_disposal(wr, _pop=_typecache.pop):
  378:     _pop(wr, None)
       
       
    2: class _TypeMetaclass(ABCMeta):
    1:     """
           A metaclass that will intern instances after they are created.
           This is done by first creating a new instance (including calling
           __init__, which sets up the required attributes for equality
           and hashing), then looking it up in the _typecache registry.
           """
       
    1:     def __init__(cls, name, bases, orig_vars):
               # __init__ is hooked to mark whether a Type class being defined is a
               # Numba internal type (one which is defined somewhere under the `numba`
               # module) or an external type (one which is defined elsewhere, for
               # example a user defined type).
  138:         super(_TypeMetaclass, cls).__init__(name, bases, orig_vars)
  138:         root = (cls.__module__.split('.'))[0]
  138:         cls._is_internal = root == "numba"
       
    1:     def _intern(cls, inst):
               # Try to intern the created instance
 3464:         wr = weakref.ref(inst, _on_type_disposal)
 3464:         orig = _typecache.get(wr)
 3464:         orig = orig and orig()
 3464:         if orig is not None:
 1298:             return orig
               else:
 2166:             inst._code = _autoincr()
 2166:             _typecache[wr] = wr
 2166:             return inst
       
    1:     def __call__(cls, *args, **kwargs):
               """
               Instantiate *cls* (a Type subclass, presumably) and intern it.
               If an interned instance already exists, it is returned, otherwise
               the new instance is returned.
               """
 3458:         inst = type.__call__(cls, *args, **kwargs)
 3458:         return cls._intern(inst)
       
       
    1: def _type_reconstructor(reconstructor, reconstructor_args, state):
           """
           Rebuild function for unpickling types.
           """
    6:     obj = reconstructor(*reconstructor_args)
    6:     if state:
    6:         obj.__dict__.update(state)
    6:     return type(obj)._intern(obj)
       
       
    2: class Type(metaclass=_TypeMetaclass):
    1:     """
           The base class for all Numba types.
           It is essential that proper equality comparison is implemented.  The
           default implementation uses the "key" property (overridable in subclasses)
           for both comparison and hashing, to ensure sane behaviour.
           """
       
    1:     mutable = False
           # Rather the type is reflected at the python<->nopython boundary
    1:     reflected = False
       
    1:     def __init__(self, name):
 3458:         self.name = name
       
    2:     @property
    2:     def key(self):
               """
               A property used for __eq__, __ne__ and __hash__.  Can be overridden
               in subclasses.
               """
52606:         return self.name
       
    2:     @property
    2:     def mangling_args(self):
               """
               Returns `(basename, args)` where `basename` is the name of the type
               and `args` is a sequence of parameters of the type.
       
               Subclass should override to specialize the behavior.
               By default, this returns `(self.name, ())`.
               """
   28:         return self.name, ()
       
    1:     def __repr__(self):
 1866:         return self.name
       
    1:     def __str__(self):
 3106:         return self.name
       
    1:     def __hash__(self):
44369:         return hash(self.key)
       
    1:     def __eq__(self, other):
22413:         return self.__class__ is other.__class__ and self.key == other.key
       
    1:     def __ne__(self, other):
 4135:         return not (self == other)
       
    1:     def __reduce__(self):
               reconstructor, args, state = super(Type, self).__reduce__()
               return (_type_reconstructor, (reconstructor, args, state))
       
    1:     def unify(self, typingctx, other):
               """
               Try to unify this type with the *other*.  A third type must
               be returned, or None if unification is not possible.
               Only override this if the coercion logic cannot be expressed
               as simple casting rules.
               """
   18:         return None
       
    1:     def can_convert_to(self, typingctx, other):
               """
               Check whether this type can be converted to the *other*.
               If successful, must return a string describing the conversion, e.g.
               "exact", "promote", "unsafe", "safe"; otherwise None is returned.
               """
   48:         return None
       
    1:     def can_convert_from(self, typingctx, other):
               """
               Similar to *can_convert_to*, but in reverse.  Only needed if
               the type provides conversion from other types.
               """
   64:         return None
       
    1:     def is_precise(self):
               """
               Whether this type is precise, i.e. can be part of a successful
               type inference.  Default implementation returns True.
               """
 1894:         return True
       
    1:     def augment(self, other):
               """
               Augment this type with the *other*.  Return the augmented type,
               or None if not supported.
               """
               return None
       
           # User-facing helpers.  These are not part of the core Type API but
           # are provided so that users can write e.g. `numba.boolean(1.5)`
           # (returns True) or `types.int32(types.int32[:])` (returns something
           # usable as a function signature).
       
    1:     def __call__(self, *args):
   29:         from numba.core.typing import signature
   29:         if len(args) == 1 and not isinstance(args[0], Type):
    8:             return self.cast_python_value(args[0])
   42:         return signature(self, # return_type
   21:                          *args)
       
    1:     def __getitem__(self, args):
               """
               Return an array of this type.
               """
   12:         from numba.core.types import Array
   12:         ndim, layout = self._determine_array_spec(args)
   12:         return Array(dtype=self, ndim=ndim, layout=layout)
       
    1:     def _determine_array_spec(self, args):
               # XXX non-contiguous by default, even for 1d arrays,
               # doesn't sound very intuitive
   12:         def validate_slice(s):
   24:             return isinstance(s, slice) and s.start is None and s.stop is None
       
   12:         if isinstance(args, (tuple, list)) and all(map(validate_slice, args)):
   12:             ndim = len(args)
   12:             if args[0].step == 1:
                       layout = 'F'
   12:             elif args[-1].step == 1:
                       layout = 'C'
                   else:
   12:                 layout = 'A'
               elif validate_slice(args):
                   ndim = 1
                   if args.step == 1:
                       layout = 'C'
                   else:
                       layout = 'A'
               else:
                   # Raise a KeyError to not be handled by collection constructors (e.g. list).
                   raise KeyError(f"Can only index numba types with slices with no start or stop, got {args}.")
       
   12:         return ndim, layout
       
    1:     def cast_python_value(self, args):
               raise NotImplementedError
       
       
    2:     @property
    2:     def is_internal(self):
               """ Returns True if this class is an internally defined Numba type by
               virtue of the module in which it is instantiated, False else."""
    8:         return self._is_internal
       
    1:     def dump(self, tab=''):
               print(f'{tab}DUMP {type(self).__name__}[code={self._code}, name={self.name}]')
       
       # XXX we should distinguish between Dummy (no meaningful
       # representation, e.g. None or a builtin function) and Opaque (has a
       # meaningful representation, e.g. ExternalFunctionPointer)
       
    2: class Dummy(Type):
    1:     """
           Base class for types that do not really have a representation and are
           compatible with a void*.
           """
       
       
    2: class Hashable(Type):
    1:     """
           Base class for hashable types.
           """
       
       
    2: class Number(Hashable):
    1:     """
           Base class for number types.
           """
       
    1:     def unify(self, typingctx, other):
               """
               Unify the two number types using Numpy's rules.
               """
    8:         from numba.np import numpy_support
    8:         if isinstance(other, Number):
                   # XXX: this can produce unsafe conversions,
                   # e.g. would unify {int64, uint64} to float64
    8:             a = numpy_support.as_dtype(self)
    8:             b = numpy_support.as_dtype(other)
    8:             sel = np.promote_types(a, b)
    8:             return numpy_support.from_dtype(sel)
       
       
    2: class Callable(Type):
    1:     """
           Base class for callables.
           """
       
    2:     @abstractmethod
    2:     def get_call_type(self, context, args, kws):
               """
               Using the typing *context*, resolve the callable's signature for
               the given arguments.  A signature object is returned, or None.
               """
       
    2:     @abstractmethod
    2:     def get_call_signatures(self):
               """
               Returns a tuple of (list of signatures, parameterized)
               """
       
    2:     @abstractmethod
    2:     def get_impl_key(self, sig):
               """
               Returns the impl key for the given signature
               """
       
       
    2: class DTypeSpec(Type):
    1:     """
           Base class for types usable as "dtype" arguments to various Numpy APIs
           (e.g. np.empty()).
           """
       
    2:     @abstractproperty
    2:     def dtype(self):
               """
               The actual dtype denoted by this dtype spec (a Type instance).
               """
       
       
    2: class IterableType(Type):
    1:     """
           Base class for iterable types.
           """
       
    2:     @abstractproperty
    2:     def iterator_type(self):
               """
               The iterator type obtained when calling iter() (explicitly or implicitly).
               """
       
       
    2: class Sized(Type):
    1:     """
           Base class for objects that support len()
           """
       
       
    2: class ConstSized(Sized):
    1:     """
           For types that have a constant size
           """
    2:     @abstractmethod
    2:     def __len__(self):
               pass
       
       
    2: class IteratorType(IterableType):
    1:     """
           Base class for all iterator types.
           Derived classes should implement the *yield_type* attribute.
           """
       
    1:     def __init__(self, name, **kwargs):
   12:         super(IteratorType, self).__init__(name, **kwargs)
       
    2:     @abstractproperty
    2:     def yield_type(self):
               """
               The type of values yielded by the iterator.
               """
       
           # This is a property to avoid recursivity (for pickling)
       
    2:     @property
    2:     def iterator_type(self):
               return self
       
       
    2: class Container(Sized, IterableType):
    1:     """
           Base class for container types.
           """
       
       
    2: class Sequence(Container):
    1:     """
           Base class for 1d sequence types.  Instances should have the *dtype*
           attribute.
           """
       
       
    2: class MutableSequence(Sequence):
    1:     """
           Base class for 1d mutable sequence types.  Instances should have the
           *dtype* attribute.
           """
       
       
    2: class ArrayCompatible(Type):
    1:     """
           Type class for Numpy array-compatible objects (typically, objects
           exposing an __array__ method).
           Derived classes should implement the *as_array* attribute.
           """
           # If overridden by a subclass, it should also implement typing
           # for '__array_wrap__' with arguments (input, formal result).
    1:     array_priority = 0.0
       
    2:     @abstractproperty
    2:     def as_array(self):
               """
               The equivalent array type, for operations supporting array-compatible
               objects (such as ufuncs).
               """
       
           # For compatibility with types.Array
       
    2:     @cached_property
    2:     def ndim(self):
               return self.as_array.ndim
       
    2:     @cached_property
    2:     def layout(self):
               return self.as_array.layout
       
    2:     @cached_property
    2:     def dtype(self):
               return self.as_array.dtype
       
       
    2: class Literal(Type):
    1:     """Base class for Literal types.
           Literal types contain the original Python value in the type.
       
           A literal type should always be constructed from the `literal(val)`
           function.
           """
       
           # *ctor_map* is a dictionary mapping Python types to Literal subclasses
           # for constructing a numba type for a given Python type.
           # It is used in `literal(val)` function.
           # To add new Literal subclass, register a new mapping to this dict.
    1:     ctor_map: ptDict[type, ptType['Literal']] = {}
       
           # *_literal_type_cache* is used to cache the numba type of the given value.
    1:     _literal_type_cache = None
       
    1:     def __init__(self, value):
               if type(self) is Literal:
                   raise TypeError(
                       "Cannot be constructed directly. "
                       "Use `numba.types.literal(value)` instead",
                   )
               self._literal_init(value)
               fmt = "Literal[{}]({})"
               super(Literal, self).__init__(fmt.format(type(value).__name__, value))
       
    1:     def _literal_init(self, value):
   66:         self._literal_value = value
               # We want to support constants of non-hashable values, therefore
               # fall back on the value's id() if necessary.
   66:         self._key = get_hashable_key(value)
       
    2:     @property
    2:     def literal_value(self):
  104:         return self._literal_value
       
    2:     @property
    2:     def literal_type(self):
  493:         if self._literal_type_cache is None:
   61:             from numba.core import typing
   61:             ctx = typing.Context()
   61:             try:
   61:                 res = ctx.resolve_value_type(self.literal_value)
                   except ValueError as e:
       
                       if "Int value is too large" in str(e):
                           # If a string literal cannot create an IntegerLiteral
                           # because of overflow we generate this message.
                           msg = f"Cannot create literal type. {str(e)}"
                           raise TypeError(msg)
                       # Not all literal types have a literal_value that can be
                       # resolved to a type, for example, LiteralStrKeyDict has a
                       # literal_value that is a python dict for which there's no
                       # `typeof` support.
                       msg = "{} has no attribute 'literal_type'".format(self)
                       raise AttributeError(msg)
   61:             self._literal_type_cache = res
       
  493:         return self._literal_type_cache
       
       
       
    2: class TypeRef(Dummy):
    1:     """Reference to a type.
       
           Used when a type is passed as a value.
           """
    1:     def __init__(self, instance_type):
   11:         self.instance_type = instance_type
   11:         super(TypeRef, self).__init__('typeref[{}]'.format(self.instance_type))
       
    2:     @property
    2:     def key(self):
  392:         return self.instance_type
       
       
    2: class InitialValue(object):
    1:     """
           Used as a mixin for a type will potentially have an initial value that will
           be carried in the .initial_value attribute.
           """
    1:     def __init__(self, initial_value):
               self._initial_value = initial_value
       
    2:     @property
    2:     def initial_value(self):
               return self._initial_value
       
       
    2: class Poison(Type):
    1:     """
           This is the "bottom" type in the type system. It won't unify and it's
           unliteral version is Poison of itself. It's advisable for debugging purposes
           to call the constructor with the type that's being poisoned (for whatever
           reason) but this isn't strictly required.
           """
    1:     def __init__(self, ty):
               self.ty = ty
               super(Poison, self).__init__(name="Poison<%s>" % ty)
       
    1:     def __unliteral__(self):
               return Poison(self)
       
    1:     def unify(self, typingctx, other):
               return None
