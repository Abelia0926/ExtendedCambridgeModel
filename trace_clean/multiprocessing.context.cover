    1: import os
    1: import sys
    1: import threading
       
    1: from . import process
    1: from . import reduction
       
    1: __all__ = ()
       
       #
       # Exceptions
       #
       
    2: class ProcessError(Exception):
    1:     pass
       
    2: class BufferTooShort(ProcessError):
    1:     pass
       
    2: class TimeoutError(ProcessError):
    1:     pass
       
    2: class AuthenticationError(ProcessError):
    1:     pass
       
       #
       # Base type for contexts. Bound methods of an instance of this type are included in __all__ of __init__.py
       #
       
    2: class BaseContext(object):
       
    1:     ProcessError = ProcessError
    1:     BufferTooShort = BufferTooShort
    1:     TimeoutError = TimeoutError
    1:     AuthenticationError = AuthenticationError
       
    1:     current_process = staticmethod(process.current_process)
    1:     parent_process = staticmethod(process.parent_process)
    1:     active_children = staticmethod(process.active_children)
       
    1:     def cpu_count(self):
               '''Returns the number of CPUs in the system'''
               num = os.cpu_count()
               if num is None:
                   raise NotImplementedError('cannot determine number of cpus')
               else:
                   return num
       
    1:     def Manager(self):
               '''Returns a manager associated with a running server process
       
               The managers methods such as `Lock()`, `Condition()` and `Queue()`
               can be used to create shared objects.
               '''
               from .managers import SyncManager
               m = SyncManager(ctx=self.get_context())
               m.start()
               return m
       
    1:     def Pipe(self, duplex=True):
               '''Returns two connection object connected by a pipe'''
               from .connection import Pipe
               return Pipe(duplex)
       
    1:     def Lock(self):
               '''Returns a non-recursive lock object'''
               from .synchronize import Lock
               return Lock(ctx=self.get_context())
       
    1:     def RLock(self):
               '''Returns a recursive lock object'''
    1:         from .synchronize import RLock
    1:         return RLock(ctx=self.get_context())
       
    1:     def Condition(self, lock=None):
               '''Returns a condition object'''
               from .synchronize import Condition
               return Condition(lock, ctx=self.get_context())
       
    1:     def Semaphore(self, value=1):
               '''Returns a semaphore object'''
               from .synchronize import Semaphore
               return Semaphore(value, ctx=self.get_context())
       
    1:     def BoundedSemaphore(self, value=1):
               '''Returns a bounded semaphore object'''
               from .synchronize import BoundedSemaphore
               return BoundedSemaphore(value, ctx=self.get_context())
       
    1:     def Event(self):
               '''Returns an event object'''
               from .synchronize import Event
               return Event(ctx=self.get_context())
       
    1:     def Barrier(self, parties, action=None, timeout=None):
               '''Returns a barrier object'''
               from .synchronize import Barrier
               return Barrier(parties, action, timeout, ctx=self.get_context())
       
    1:     def Queue(self, maxsize=0):
               '''Returns a queue object'''
               from .queues import Queue
               return Queue(maxsize, ctx=self.get_context())
       
    1:     def JoinableQueue(self, maxsize=0):
               '''Returns a queue object'''
               from .queues import JoinableQueue
               return JoinableQueue(maxsize, ctx=self.get_context())
       
    1:     def SimpleQueue(self):
               '''Returns a queue object'''
               from .queues import SimpleQueue
               return SimpleQueue(ctx=self.get_context())
       
    2:     def Pool(self, processes=None, initializer=None, initargs=(),
    1:              maxtasksperchild=None):
               '''Returns a process pool object'''
               from .pool import Pool
               return Pool(processes, initializer, initargs, maxtasksperchild,
                           context=self.get_context())
       
    1:     def RawValue(self, typecode_or_type, *args):
               '''Returns a shared object'''
               from .sharedctypes import RawValue
               return RawValue(typecode_or_type, *args)
       
    1:     def RawArray(self, typecode_or_type, size_or_initializer):
               '''Returns a shared array'''
               from .sharedctypes import RawArray
               return RawArray(typecode_or_type, size_or_initializer)
       
    1:     def Value(self, typecode_or_type, *args, lock=True):
               '''Returns a synchronized shared object'''
               from .sharedctypes import Value
               return Value(typecode_or_type, *args, lock=lock,
                            ctx=self.get_context())
       
    1:     def Array(self, typecode_or_type, size_or_initializer, *, lock=True):
               '''Returns a synchronized shared array'''
               from .sharedctypes import Array
               return Array(typecode_or_type, size_or_initializer, lock=lock,
                            ctx=self.get_context())
       
    1:     def freeze_support(self):
               '''Check whether this is a fake forked process in a frozen executable.
               If so then run code specified by commandline and exit.
               '''
               if sys.platform == 'win32' and getattr(sys, 'frozen', False):
                   from .spawn import freeze_support
                   freeze_support()
       
    1:     def get_logger(self):
               '''Return package logger -- if it does not already exist then
               it is created.
               '''
               from .util import get_logger
               return get_logger()
       
    1:     def log_to_stderr(self, level=None):
               '''Turn on logging and add a handler which prints to stderr'''
               from .util import log_to_stderr
               return log_to_stderr(level)
       
    1:     def allow_connection_pickling(self):
               '''Install support for sending connections and sockets
               between processes
               '''
               # This is undocumented.  In previous versions of multiprocessing
               # its only effect was to make socket objects inheritable on Windows.
               from . import connection
       
    1:     def set_executable(self, executable):
               '''Sets the path to a python.exe or pythonw.exe binary used to run
               child processes instead of sys.executable when using the 'spawn'
               start method.  Useful for people embedding Python.
               '''
               from .spawn import set_executable
               set_executable(executable)
       
    1:     def set_forkserver_preload(self, module_names):
               '''Set list of module names to try to load in forkserver process.
               This is really just a hint.
               '''
               from .forkserver import set_forkserver_preload
               set_forkserver_preload(module_names)
       
    1:     def get_context(self, method=None):
               if method is None:
                   return self
               try:
                   ctx = _concrete_contexts[method]
               except KeyError:
                   raise ValueError('cannot find context for %r' % method) from None
               ctx._check_available()
               return ctx
       
    1:     def get_start_method(self, allow_none=False):
    1:         return self._name
       
    1:     def set_start_method(self, method, force=False):
               raise ValueError('cannot set start method of concrete context')
       
    2:     @property
    2:     def reducer(self):
               '''Controls how objects will be reduced to a form that can be
               shared with other processes.'''
    1:         return globals().get('reduction')
       
    2:     @reducer.setter
    2:     def reducer(self, reduction):
               globals()['reduction'] = reduction
       
    1:     def _check_available(self):
               pass
       
       #
       # Type of default context -- underlying context can be set at most once
       #
       
    2: class Process(process.BaseProcess):
    1:     _start_method = None
    2:     @staticmethod
    2:     def _Popen(process_obj):
               return _default_context.get_context().Process._Popen(process_obj)
       
    2:     @staticmethod
    2:     def _after_fork():
               return _default_context.get_context().Process._after_fork()
       
    2: class DefaultContext(BaseContext):
    1:     Process = Process
       
    1:     def __init__(self, context):
    1:         self._default_context = context
    1:         self._actual_context = None
       
    1:     def get_context(self, method=None):
    1:         if method is None:
    1:             if self._actual_context is None:
    1:                 self._actual_context = self._default_context
    1:             return self._actual_context
               else:
                   return super().get_context(method)
       
    1:     def set_start_method(self, method, force=False):
               if self._actual_context is not None and not force:
                   raise RuntimeError('context has already been set')
               if method is None and force:
                   self._actual_context = None
                   return
               self._actual_context = self.get_context(method)
       
    1:     def get_start_method(self, allow_none=False):
               if self._actual_context is None:
                   if allow_none:
                       return None
                   self._actual_context = self._default_context
               return self._actual_context._name
       
    1:     def get_all_start_methods(self):
               if sys.platform == 'win32':
                   return ['spawn']
               else:
                   methods = ['spawn', 'fork'] if sys.platform == 'darwin' else ['fork', 'spawn']
                   if reduction.HAVE_SEND_HANDLE:
                       methods.append('forkserver')
                   return methods
       
       
       #
       # Context types for fixed start method
       #
       
    1: if sys.platform != 'win32':
       
    2:     class ForkProcess(process.BaseProcess):
    1:         _start_method = 'fork'
    2:         @staticmethod
    2:         def _Popen(process_obj):
                   from .popen_fork import Popen
                   return Popen(process_obj)
       
    2:     class SpawnProcess(process.BaseProcess):
    1:         _start_method = 'spawn'
    2:         @staticmethod
    2:         def _Popen(process_obj):
                   from .popen_spawn_posix import Popen
                   return Popen(process_obj)
       
    2:         @staticmethod
    2:         def _after_fork():
                   # process is spawned, nothing to do
                   pass
       
    2:     class ForkServerProcess(process.BaseProcess):
    1:         _start_method = 'forkserver'
    2:         @staticmethod
    2:         def _Popen(process_obj):
                   from .popen_forkserver import Popen
                   return Popen(process_obj)
       
    2:     class ForkContext(BaseContext):
    1:         _name = 'fork'
    1:         Process = ForkProcess
       
    2:     class SpawnContext(BaseContext):
    1:         _name = 'spawn'
    1:         Process = SpawnProcess
       
    2:     class ForkServerContext(BaseContext):
    1:         _name = 'forkserver'
    1:         Process = ForkServerProcess
    1:         def _check_available(self):
                   if not reduction.HAVE_SEND_HANDLE:
                       raise ValueError('forkserver start method not available')
       
    1:     _concrete_contexts = {
    1:         'fork': ForkContext(),
    1:         'spawn': SpawnContext(),
    1:         'forkserver': ForkServerContext(),
           }
    1:     if sys.platform == 'darwin':
               # bpo-33725: running arbitrary code after fork() is no longer reliable
               # on macOS since macOS 10.14 (Mojave). Use spawn by default instead.
    1:         _default_context = DefaultContext(_concrete_contexts['spawn'])
           else:
               _default_context = DefaultContext(_concrete_contexts['fork'])
       
       else:
       
           class SpawnProcess(process.BaseProcess):
               _start_method = 'spawn'
               @staticmethod
               def _Popen(process_obj):
                   from .popen_spawn_win32 import Popen
                   return Popen(process_obj)
       
               @staticmethod
               def _after_fork():
                   # process is spawned, nothing to do
                   pass
       
           class SpawnContext(BaseContext):
               _name = 'spawn'
               Process = SpawnProcess
       
           _concrete_contexts = {
               'spawn': SpawnContext(),
           }
           _default_context = DefaultContext(_concrete_contexts['spawn'])
       
       #
       # Force the start method
       #
       
    1: def _force_start_method(method):
           _default_context._actual_context = _concrete_contexts[method]
       
       #
       # Check that the current thread is spawning a child process
       #
       
    1: _tls = threading.local()
       
    1: def get_spawning_popen():
           return getattr(_tls, 'spawning_popen', None)
       
    1: def set_spawning_popen(popen):
           _tls.spawning_popen = popen
       
    1: def assert_spawning(obj):
           if get_spawning_popen() is None:
               raise RuntimeError(
                   '%s objects should only be shared between processes'
                   ' through inheritance' % type(obj).__name__
                   )
