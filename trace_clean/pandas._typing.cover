    1: from __future__ import annotations
       
    1: from collections.abc import (
           Hashable,
           Iterator,
           Mapping,
           MutableMapping,
           Sequence,
       )
    1: from datetime import (
           date,
           datetime,
           timedelta,
           tzinfo,
       )
    1: from os import PathLike
    1: import sys
    1: from typing import (
           TYPE_CHECKING,
           Any,
           Callable,
           Literal,
           Optional,
           Protocol,
           Type as type_t,
           TypeVar,
           Union,
           overload,
       )
       
    1: import numpy as np
       
       # To prevent import cycles place any internal imports in the branch below
       # and use a string literal forward reference to it in subsequent types
       # https://mypy.readthedocs.io/en/latest/common_issues.html#import-cycles
    1: if TYPE_CHECKING:
           import numpy.typing as npt
       
           from pandas._libs import (
               NaTType,
               Period,
               Timedelta,
               Timestamp,
           )
           from pandas._libs.tslibs import BaseOffset
       
           from pandas.core.dtypes.dtypes import ExtensionDtype
       
           from pandas import Interval
           from pandas.arrays import (
               DatetimeArray,
               TimedeltaArray,
           )
           from pandas.core.arrays.base import ExtensionArray
           from pandas.core.frame import DataFrame
           from pandas.core.generic import NDFrame
           from pandas.core.groupby.generic import (
               DataFrameGroupBy,
               GroupBy,
               SeriesGroupBy,
           )
           from pandas.core.indexes.base import Index
           from pandas.core.internals import (
               ArrayManager,
               BlockManager,
               SingleArrayManager,
               SingleBlockManager,
           )
           from pandas.core.resample import Resampler
           from pandas.core.series import Series
           from pandas.core.window.rolling import BaseWindow
       
           from pandas.io.formats.format import EngFormatter
           from pandas.tseries.holiday import AbstractHolidayCalendar
       
           ScalarLike_co = Union[
               int,
               float,
               complex,
               str,
               bytes,
               np.generic,
           ]
       
           # numpy compatible types
           NumpyValueArrayLike = Union[ScalarLike_co, npt.ArrayLike]
           # Name "npt._ArrayLikeInt_co" is not defined  [name-defined]
           NumpySorter = Optional[npt._ArrayLikeInt_co]  # type: ignore[name-defined]
       
           from typing import SupportsIndex
       
           if sys.version_info >= (3, 10):
               from typing import TypeGuard  # pyright: ignore[reportUnusedImport]
           else:
               from typing_extensions import TypeGuard  # pyright: ignore[reportUnusedImport]
       
           if sys.version_info >= (3, 11):
               from typing import Self  # pyright: ignore[reportUnusedImport]
           else:
               from typing_extensions import Self  # pyright: ignore[reportUnusedImport]
       else:
    1:     npt: Any = None
    1:     Self: Any = None
    1:     TypeGuard: Any = None
       
    1: HashableT = TypeVar("HashableT", bound=Hashable)
    1: MutableMappingT = TypeVar("MutableMappingT", bound=MutableMapping)
       
       # array-like
       
    1: ArrayLike = Union["ExtensionArray", np.ndarray]
    1: AnyArrayLike = Union[ArrayLike, "Index", "Series"]
    1: TimeArrayLike = Union["DatetimeArray", "TimedeltaArray"]
       
       # list-like
       
       # from https://github.com/hauntsaninja/useful_types
       # includes Sequence-like objects but excludes str and bytes
    1: _T_co = TypeVar("_T_co", covariant=True)
       
       
    2: class SequenceNotStr(Protocol[_T_co]):
    2:     @overload
    2:     def __getitem__(self, index: SupportsIndex, /) -> _T_co:
               ...
       
    2:     @overload
    2:     def __getitem__(self, index: slice, /) -> Sequence[_T_co]:
               ...
       
    1:     def __contains__(self, value: object, /) -> bool:
               ...
       
    1:     def __len__(self) -> int:
               ...
       
    1:     def __iter__(self) -> Iterator[_T_co]:
               ...
       
    1:     def index(self, value: Any, /, start: int = 0, stop: int = ...) -> int:
               ...
       
    1:     def count(self, value: Any, /) -> int:
               ...
       
    1:     def __reversed__(self) -> Iterator[_T_co]:
               ...
       
       
    1: ListLike = Union[AnyArrayLike, SequenceNotStr, range]
       
       # scalars
       
    1: PythonScalar = Union[str, float, bool]
    1: DatetimeLikeScalar = Union["Period", "Timestamp", "Timedelta"]
    1: PandasScalar = Union["Period", "Timestamp", "Timedelta", "Interval"]
    1: Scalar = Union[PythonScalar, PandasScalar, np.datetime64, np.timedelta64, date]
    1: IntStrT = TypeVar("IntStrT", bound=Union[int, str])
       
       
       # timestamp and timedelta convertible types
       
    2: TimestampConvertibleTypes = Union[
    1:     "Timestamp", date, np.datetime64, np.int64, float, str
       ]
    2: TimestampNonexistent = Union[
    1:     Literal["shift_forward", "shift_backward", "NaT", "raise"], timedelta
       ]
    2: TimedeltaConvertibleTypes = Union[
    1:     "Timedelta", timedelta, np.timedelta64, np.int64, float, str
       ]
    1: Timezone = Union[str, tzinfo]
       
    1: ToTimestampHow = Literal["s", "e", "start", "end"]
       
       # NDFrameT is stricter and ensures that the same subclass of NDFrame always is
       # used. E.g. `def func(a: NDFrameT) -> NDFrameT: ...` means that if a
       # Series is passed into a function, a Series is always returned and if a DataFrame is
       # passed in, a DataFrame is always returned.
    1: NDFrameT = TypeVar("NDFrameT", bound="NDFrame")
       
    1: NumpyIndexT = TypeVar("NumpyIndexT", np.ndarray, "Index")
       
    1: AxisInt = int
    1: Axis = Union[AxisInt, Literal["index", "columns", "rows"]]
    1: IndexLabel = Union[Hashable, Sequence[Hashable]]
    1: Level = Hashable
    1: Shape = tuple[int, ...]
    1: Suffixes = tuple[Optional[str], Optional[str]]
    1: Ordered = Optional[bool]
    1: JSONSerializable = Optional[Union[PythonScalar, list, dict]]
    1: Frequency = Union[str, "BaseOffset"]
    1: Axes = ListLike
       
    2: RandomState = Union[
    2:     int,
    1:     np.ndarray,
    1:     np.random.Generator,
    1:     np.random.BitGenerator,
    1:     np.random.RandomState,
       ]
       
       # dtypes
    1: NpDtype = Union[str, np.dtype, type_t[Union[str, complex, bool, object]]]
    1: Dtype = Union["ExtensionDtype", NpDtype]
    1: AstypeArg = Union["ExtensionDtype", "npt.DTypeLike"]
       # DtypeArg specifies all allowable dtypes in a functions its dtype argument
    1: DtypeArg = Union[Dtype, dict[Hashable, Dtype]]
    1: DtypeObj = Union[np.dtype, "ExtensionDtype"]
       
       # converters
    1: ConvertersArg = dict[Hashable, Callable[[Dtype], Dtype]]
       
       # parse_dates
    2: ParseDatesArg = Union[
    1:     bool, list[Hashable], list[list[Hashable]], dict[Hashable, list[Hashable]]
       ]
       
       # For functions like rename that convert one label to another
    1: Renamer = Union[Mapping[Any, Hashable], Callable[[Any], Hashable]]
       
       # to maintain type information across generic functions and parametrization
    1: T = TypeVar("T")
       
       # used in decorators to preserve the signature of the function it decorates
       # see https://mypy.readthedocs.io/en/stable/generics.html#declaring-decorators
    1: FuncType = Callable[..., Any]
    1: F = TypeVar("F", bound=FuncType)
       
       # types of vectorized key functions for DataFrame::sort_values and
       # DataFrame::sort_index, among others
    1: ValueKeyFunc = Optional[Callable[["Series"], Union["Series", AnyArrayLike]]]
    1: IndexKeyFunc = Optional[Callable[["Index"], Union["Index", AnyArrayLike]]]
       
       # types of `func` kwarg for DataFrame.aggregate and Series.aggregate
    1: AggFuncTypeBase = Union[Callable, str]
    2: AggFuncTypeDict = MutableMapping[
    1:     Hashable, Union[AggFuncTypeBase, list[AggFuncTypeBase]]
       ]
    2: AggFuncType = Union[
    2:     AggFuncTypeBase,
    1:     list[AggFuncTypeBase],
    1:     AggFuncTypeDict,
       ]
    2: AggObjType = Union[
    1:     "Series",
           "DataFrame",
           "GroupBy",
           "SeriesGroupBy",
           "DataFrameGroupBy",
           "BaseWindow",
           "Resampler",
       ]
       
    1: PythonFuncType = Callable[[Any], Any]
       
       # filenames and file-like-objects
    1: AnyStr_co = TypeVar("AnyStr_co", str, bytes, covariant=True)
    1: AnyStr_contra = TypeVar("AnyStr_contra", str, bytes, contravariant=True)
       
       
    2: class BaseBuffer(Protocol):
    2:     @property
    2:     def mode(self) -> str:
               # for _get_filepath_or_buffer
               ...
       
    1:     def seek(self, __offset: int, __whence: int = ...) -> int:
               # with one argument: gzip.GzipFile, bz2.BZ2File
               # with two arguments: zip.ZipFile, read_sas
               ...
       
    1:     def seekable(self) -> bool:
               # for bz2.BZ2File
               ...
       
    1:     def tell(self) -> int:
               # for zip.ZipFile, read_stata, to_stata
               ...
       
       
    2: class ReadBuffer(BaseBuffer, Protocol[AnyStr_co]):
    1:     def read(self, __n: int = ...) -> AnyStr_co:
               # for BytesIOWrapper, gzip.GzipFile, bz2.BZ2File
               ...
       
       
    2: class WriteBuffer(BaseBuffer, Protocol[AnyStr_contra]):
    1:     def write(self, __b: AnyStr_contra) -> Any:
               # for gzip.GzipFile, bz2.BZ2File
               ...
       
    1:     def flush(self) -> Any:
               # for gzip.GzipFile, bz2.BZ2File
               ...
       
       
    2: class ReadPickleBuffer(ReadBuffer[bytes], Protocol):
    1:     def readline(self) -> bytes:
               ...
       
       
    2: class WriteExcelBuffer(WriteBuffer[bytes], Protocol):
    1:     def truncate(self, size: int | None = ...) -> int:
               ...
       
       
    2: class ReadCsvBuffer(ReadBuffer[AnyStr_co], Protocol):
    1:     def __iter__(self) -> Iterator[AnyStr_co]:
               # for engine=python
               ...
       
    1:     def fileno(self) -> int:
               # for _MMapWrapper
               ...
       
    1:     def readline(self) -> AnyStr_co:
               # for engine=python
               ...
       
    2:     @property
    2:     def closed(self) -> bool:
               # for enine=pyarrow
               ...
       
       
    1: FilePath = Union[str, "PathLike[str]"]
       
       # for arbitrary kwargs passed during reading/writing files
    1: StorageOptions = Optional[dict[str, Any]]
       
       
       # compression keywords and compression
    1: CompressionDict = dict[str, Any]
    2: CompressionOptions = Optional[
    1:     Union[Literal["infer", "gzip", "bz2", "zip", "xz", "zstd", "tar"], CompressionDict]
       ]
       
       # types in DataFrameFormatter
    2: FormattersType = Union[
    1:     list[Callable], tuple[Callable, ...], Mapping[Union[str, int], Callable]
       ]
    1: ColspaceType = Mapping[Hashable, Union[str, int]]
    1: FloatFormatType = Union[str, Callable, "EngFormatter"]
    2: ColspaceArgType = Union[
    1:     str, int, Sequence[Union[str, int]], Mapping[Hashable, Union[str, int]]
       ]
       
       # Arguments for fillna()
    1: FillnaOptions = Literal["backfill", "bfill", "ffill", "pad"]
    2: InterpolateOptions = Literal[
    1:     "linear",
           "time",
           "index",
           "values",
           "nearest",
           "zero",
           "slinear",
           "quadratic",
           "cubic",
           "barycentric",
           "polynomial",
           "krogh",
           "piecewise_polynomial",
           "spline",
           "pchip",
           "akima",
           "cubicspline",
           "from_derivatives",
       ]
       
       # internals
    2: Manager = Union[
    1:     "ArrayManager", "SingleArrayManager", "BlockManager", "SingleBlockManager"
       ]
    1: SingleManager = Union["SingleArrayManager", "SingleBlockManager"]
    1: Manager2D = Union["ArrayManager", "BlockManager"]
       
       # indexing
       # PositionalIndexer -> valid 1D positional indexer, e.g. can pass
       # to ndarray.__getitem__
       # ScalarIndexer is for a single value as the index
       # SequenceIndexer is for list like or slices (but not tuples)
       # PositionalIndexerTuple is extends the PositionalIndexer for 2D arrays
       # These are used in various __getitem__ overloads
       # TODO(typing#684): add Ellipsis, see
       # https://github.com/python/typing/issues/684#issuecomment-548203158
       # https://bugs.python.org/issue41810
       # Using List[int] here rather than Sequence[int] to disallow tuples.
    1: ScalarIndexer = Union[int, np.integer]
    1: SequenceIndexer = Union[slice, list[int], np.ndarray]
    1: PositionalIndexer = Union[ScalarIndexer, SequenceIndexer]
    1: PositionalIndexerTuple = tuple[PositionalIndexer, PositionalIndexer]
    1: PositionalIndexer2D = Union[PositionalIndexer, PositionalIndexerTuple]
    1: if TYPE_CHECKING:
           TakeIndexer = Union[Sequence[int], Sequence[np.integer], npt.NDArray[np.integer]]
       else:
    1:     TakeIndexer = Any
       
       # Shared by functions such as drop and astype
    1: IgnoreRaise = Literal["ignore", "raise"]
       
       # Windowing rank methods
    1: WindowingRankType = Literal["average", "min", "max"]
       
       # read_csv engines
    1: CSVEngine = Literal["c", "python", "pyarrow", "python-fwf"]
       
       # read_json engines
    1: JSONEngine = Literal["ujson", "pyarrow"]
       
       # read_xml parsers
    1: XMLParsers = Literal["lxml", "etree"]
       
       # read_html flavors
    1: HTMLFlavors = Literal["lxml", "html5lib", "bs4"]
       
       # Interval closed type
    1: IntervalLeftRight = Literal["left", "right"]
    1: IntervalClosedType = Union[IntervalLeftRight, Literal["both", "neither"]]
       
       # datetime and NaTType
    1: DatetimeNaTType = Union[datetime, "NaTType"]
    1: DateTimeErrorChoices = Union[IgnoreRaise, Literal["coerce"]]
       
       # sort_index
    1: SortKind = Literal["quicksort", "mergesort", "heapsort", "stable"]
    1: NaPosition = Literal["first", "last"]
       
       # Arguments for nsmalles and n_largest
    1: NsmallestNlargestKeep = Literal["first", "last", "all"]
       
       # quantile interpolation
    1: QuantileInterpolation = Literal["linear", "lower", "higher", "midpoint", "nearest"]
       
       # plotting
    1: PlottingOrientation = Literal["horizontal", "vertical"]
       
       # dropna
    1: AnyAll = Literal["any", "all"]
       
       # merge
    1: MergeHow = Literal["left", "right", "inner", "outer", "cross"]
    2: MergeValidate = Literal[
    1:     "one_to_one",
           "1:1",
           "one_to_many",
           "1:m",
           "many_to_one",
           "m:1",
           "many_to_many",
           "m:m",
       ]
       
       # join
    1: JoinHow = Literal["left", "right", "inner", "outer"]
    2: JoinValidate = Literal[
    1:     "one_to_one",
           "1:1",
           "one_to_many",
           "1:m",
           "many_to_one",
           "m:1",
           "many_to_many",
           "m:m",
       ]
       
       # reindex
    1: ReindexMethod = Union[FillnaOptions, Literal["nearest"]]
       
    1: MatplotlibColor = Union[str, Sequence[float]]
    2: TimeGrouperOrigin = Union[
    1:     "Timestamp", Literal["epoch", "start", "start_day", "end", "end_day"]
       ]
    1: TimeAmbiguous = Union[Literal["infer", "NaT", "raise"], "npt.NDArray[np.bool_]"]
    2: TimeNonexistent = Union[
    1:     Literal["shift_forward", "shift_backward", "NaT", "raise"], timedelta
       ]
    1: DropKeep = Literal["first", "last", False]
    2: CorrelationMethod = Union[
    1:     Literal["pearson", "kendall", "spearman"], Callable[[np.ndarray, np.ndarray], float]
       ]
    1: AlignJoin = Literal["outer", "inner", "left", "right"]
    1: DtypeBackend = Literal["pyarrow", "numpy_nullable"]
       
    1: TimeUnit = Literal["s", "ms", "us", "ns"]
    2: OpenFileErrors = Literal[
    1:     "strict",
           "ignore",
           "replace",
           "surrogateescape",
           "xmlcharrefreplace",
           "backslashreplace",
           "namereplace",
       ]
       
       # update
    1: UpdateJoin = Literal["left"]
       
       # applymap
    1: NaAction = Literal["ignore"]
       
       # from_dict
    1: FromDictOrient = Literal["columns", "index", "tight"]
       
       # to_gbc
    1: ToGbqIfexist = Literal["fail", "replace", "append"]
       
       # to_stata
    1: ToStataByteorder = Literal[">", "<", "little", "big"]
       
       # ExcelWriter
    1: ExcelWriterIfSheetExists = Literal["error", "new", "replace", "overlay"]
       
       # Offsets
    1: OffsetCalendar = Union[np.busdaycalendar, "AbstractHolidayCalendar"]
       
       # read_csv: usecols
    2: UsecolsArgType = Union[
    2:     SequenceNotStr[Hashable],
    1:     range,
    1:     AnyArrayLike,
    1:     Callable[[HashableT], bool],
    1:     None,
       ]
