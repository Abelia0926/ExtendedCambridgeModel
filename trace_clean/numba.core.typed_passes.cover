    1: import abc
    1: from contextlib import contextmanager
    1: from collections import defaultdict, namedtuple
    1: from functools import partial
    1: from copy import copy
    1: import warnings
       
    1: from numba.core import (errors, types, typing, ir, funcdesc, rewrites,
                               typeinfer, config, lowering)
       
    1: from numba.parfors.parfor import PreParforPass as _parfor_PreParforPass
    1: from numba.parfors.parfor import ParforPass as _parfor_ParforPass
    1: from numba.parfors.parfor import ParforFusionPass as _parfor_ParforFusionPass
    1: from numba.parfors.parfor import ParforPreLoweringPass as \
           _parfor_ParforPreLoweringPass
    1: from numba.parfors.parfor import Parfor
    1: from numba.parfors.parfor_lowering import ParforLower
       
    1: from numba.core.compiler_machinery import (FunctionPass, LoweringPass,
                                                  AnalysisPass, register_pass)
    1: from numba.core.annotations import type_annotations
    1: from numba.core.ir_utils import (raise_on_unsupported_feature, warn_deprecated,
                                        check_and_legalize_ir, guard,
                                        dead_code_elimination, simplify_CFG,
                                        get_definition,
                                        build_definitions, compute_cfg_from_blocks,
                                        is_operator_or_getitem,
                                        replace_vars)
    1: from numba.core import postproc
    1: from llvmlite import binding as llvm
       
       
       # Outputs of type inference pass
    1: _TypingResults = namedtuple("_TypingResults", [
           "typemap",
           "return_type",
           "calltypes",
           "typing_errors",
       ])
       
       
    2: @contextmanager
    2: def fallback_context(state, msg):
           """
           Wraps code that would signal a fallback to object mode
           """
   96:     try:
   96:         yield
           except Exception as e:
               if not state.status.can_fallback:
                   raise
               else:
                   # Clear all references attached to the traceback
                   e = e.with_traceback(None)
                   # this emits a warning containing the error message body in the
                   # case of fallback from npm to objmode
                   loop_lift = '' if state.flags.enable_looplift else 'OUT'
                   msg_rewrite = ("\nCompilation is falling back to object mode "
                                  "WITH%s looplifting enabled because %s"
                                  % (loop_lift, msg))
                   warnings.warn_explicit('%s due to: %s' % (msg_rewrite, e),
                                          errors.NumbaWarning,
                                          state.func_id.filename,
                                          state.func_id.firstlineno)
                   raise
       
       
    1: def type_inference_stage(typingctx, targetctx, interp, args, return_type,
    1:                          locals={}, raise_errors=True):
   24:     if len(args) != interp.arg_count:
               raise TypeError("Mismatch number of argument types")
   24:     warnings = errors.WarningsFixer(errors.NumbaWarning)
       
   24:     infer = typeinfer.TypeInferer(typingctx, interp, warnings)
   48:     callstack_ctx = typingctx.callstack.register(targetctx.target, infer,
   24:                                                  interp.func_id, args)
           # Setup two contexts: 1) callstack setup/teardown 2) flush warnings
   48:     with callstack_ctx, warnings:
               # Seed argument types
   79:         for index, (name, ty) in enumerate(zip(interp.arg_names, args)):
   55:             infer.seed_argument(name, index, ty)
       
               # Seed return type
   24:         if return_type is not None:
    7:             infer.seed_return(return_type)
       
               # Seed local types
   24:         for k, v in locals.items():
                   infer.seed_type(k, v)
       
   24:         infer.build_constraint()
               # return errors in case of partial typing
   24:         errs = infer.propagate(raise_errors=raise_errors)
   24:         typemap, restype, calltypes = infer.unify(raise_errors=raise_errors)
       
   24:     return _TypingResults(typemap, restype, calltypes, errs)
       
       
    2: class BaseTypeInference(FunctionPass):
    1:     _raise_errors = True
       
    1:     def __init__(self):
    2:         FunctionPass.__init__(self)
       
    1:     def run_pass(self, state):
               """
               Type inference and legalization
               """
   72:         with fallback_context(state, 'Function "%s" failed type inference'
   24:                               % (state.func_id.func_name,)):
                   # Type inference
   48:             typemap, return_type, calltypes, errs = type_inference_stage(
   24:                 state.typingctx,
   24:                 state.targetctx,
   24:                 state.func_ir,
   24:                 state.args,
   24:                 state.return_type,
   24:                 state.locals,
   24:                 raise_errors=self._raise_errors)
   24:             state.typemap = typemap
                   # save errors in case of partial typing
   24:             state.typing_errors = errs
   24:             if self._raise_errors:
   24:                 state.return_type = return_type
   24:             state.calltypes = calltypes
       
   24:         def legalize_return_type(return_type, interp, targetctx):
                   """
                   Only accept array return type iff it is passed into the function.
                   Reject function object return types if in nopython mode.
                   """
   24:             if (not targetctx.enable_nrt and
                           isinstance(return_type, types.Array)):
                       # Walk IR to discover all arguments and all return statements
                       retstmts = []
                       caststmts = {}
                       argvars = set()
                       for bid, blk in interp.blocks.items():
                           for inst in blk.body:
                               if isinstance(inst, ir.Return):
                                   retstmts.append(inst.value.name)
                               elif isinstance(inst, ir.Assign):
                                   if (isinstance(inst.value, ir.Expr)
                                           and inst.value.op == 'cast'):
                                       caststmts[inst.target.name] = inst.value
                                   elif isinstance(inst.value, ir.Arg):
                                       argvars.add(inst.target.name)
       
                       assert retstmts, "No return statements?"
       
                       for var in retstmts:
                           cast = caststmts.get(var)
                           if cast is None or cast.value.name not in argvars:
                               if self._raise_errors:
                                   msg = ("Only accept returning of array passed into "
                                          "the function as argument")
                                   raise errors.NumbaTypeError(msg)
       
   48:             elif (isinstance(return_type, types.Function) or
   24:                     isinstance(return_type, types.Phantom)):
                       if self._raise_errors:
                           msg = "Can't return function object ({}) in nopython mode"
                           raise errors.NumbaTypeError(msg.format(return_type))
       
   72:         with fallback_context(state, 'Function "%s" has invalid return type'
   24:                               % (state.func_id.func_name,)):
   48:             legalize_return_type(state.return_type, state.func_ir,
   24:                                  state.targetctx)
   24:         return True
       
       
    3: @register_pass(mutates_CFG=True, analysis_only=False)
    2: class NopythonTypeInference(BaseTypeInference):
    1:     _name = "nopython_type_inference"
       
       
    3: @register_pass(mutates_CFG=True, analysis_only=False)
    2: class PartialTypeInference(BaseTypeInference):
    1:     _name = "partial_type_inference"
    1:     _raise_errors = False
       
       
    3: @register_pass(mutates_CFG=False, analysis_only=False)
    2: class AnnotateTypes(AnalysisPass):
    1:     _name = "annotate_types"
       
    1:     def __init__(self):
    1:         AnalysisPass.__init__(self)
       
    1:     def get_analysis_usage(self, AU):
   48:         AU.add_required(IRLegalization)
       
    1:     def run_pass(self, state):
               """
               Create type annotation after type inference
               """
   24:         func_ir = state.func_ir.copy()
   48:         state.type_annotation = type_annotations.TypeAnnotation(
   24:             func_ir=func_ir,
   24:             typemap=state.typemap,
   24:             calltypes=state.calltypes,
   24:             lifted=state.lifted,
   24:             lifted_from=state.lifted_from,
   24:             args=state.args,
   24:             return_type=state.return_type,
   24:             html_output=config.HTML)
       
   24:         if config.ANNOTATE:
                   print("ANNOTATION".center(80, '-'))
                   print(state.type_annotation)
                   print('=' * 80)
   24:         if config.HTML:
                   with open(config.HTML, 'w') as fout:
                       state.type_annotation.html_annotate(fout)
       
   24:         return False
       
       
    3: @register_pass(mutates_CFG=True, analysis_only=False)
    2: class NopythonRewrites(FunctionPass):
    1:     _name = "nopython_rewrites"
       
    1:     def __init__(self):
    1:         FunctionPass.__init__(self)
       
    1:     def run_pass(self, state):
               """
               Perform any intermediate representation rewrites after type
               inference.
               """
               # a bunch of these passes are either making assumptions or rely on some
               # very picky and slightly bizarre state particularly in relation to
               # ir.Del presence. To accommodate, ir.Dels are added ahead of running
               # this pass and stripped at the end.
       
               # Ensure we have an IR and type information.
   24:         assert state.func_ir
   24:         assert isinstance(getattr(state, 'typemap', None), dict)
   24:         assert isinstance(getattr(state, 'calltypes', None), dict)
   24:         msg = ('Internal error in post-inference rewriting '
                      'pass encountered during compilation of '
   24:                'function "%s"' % (state.func_id.func_name,))
       
   24:         pp = postproc.PostProcessor(state.func_ir)
   24:         pp.run(True)
   48:         with fallback_context(state, msg):
   24:             rewrites.rewrite_registry.apply('after-inference', state)
   24:         pp.remove_dels()
   24:         return True
       
       
    3: @register_pass(mutates_CFG=True, analysis_only=False)
    2: class PreParforPass(FunctionPass):
       
    1:     _name = "pre_parfor_pass"
       
    1:     def __init__(self):
    1:         FunctionPass.__init__(self)
       
    1:     def run_pass(self, state):
               """
               Preprocessing for data-parallel computations.
               """
               # Ensure we have an IR and type information.
               assert state.func_ir
               preparfor_pass = _parfor_PreParforPass(
                   state.func_ir,
                   state.typemap,
                   state.calltypes,
                   state.typingctx,
                   state.targetctx,
                   state.flags.auto_parallel,
                   state.parfor_diagnostics.replaced_fns
               )
       
               preparfor_pass.run()
               return True
       
       
       # this is here so it pickles and for no other reason
    1: def _reload_parfors():
           """Reloader for cached parfors
           """
           # Re-initialize the parallel backend when load from cache.
           from numba.np.ufunc.parallel import _launch_threads
           _launch_threads()
       
       
    3: @register_pass(mutates_CFG=True, analysis_only=False)
    2: class ParforPass(FunctionPass):
       
    1:     _name = "parfor_pass"
       
    1:     def __init__(self):
    1:         FunctionPass.__init__(self)
       
    1:     def run_pass(self, state):
               """
               Convert data-parallel computations into Parfor nodes
               """
               # Ensure we have an IR and type information.
               assert state.func_ir
               parfor_pass = _parfor_ParforPass(state.func_ir,
                                                state.typemap,
                                                state.calltypes,
                                                state.return_type,
                                                state.typingctx,
                                                state.targetctx,
                                                state.flags.auto_parallel,
                                                state.flags,
                                                state.metadata,
                                                state.parfor_diagnostics)
               parfor_pass.run()
       
               # check the parfor pass worked and warn if it didn't
               has_parfor = False
               for blk in state.func_ir.blocks.values():
                   for stmnt in blk.body:
                       if isinstance(stmnt, Parfor):
                           has_parfor = True
                           break
                   else:
                       continue
                   break
       
               if not has_parfor:
                   # parfor calls the compiler chain again with a string
                   if not (config.DISABLE_PERFORMANCE_WARNINGS or
                           state.func_ir.loc.filename == '<string>'):
                       url = ("https://numba.readthedocs.io/en/stable/user/"
                              "parallel.html#diagnostics")
                       msg = ("\nThe keyword argument 'parallel=True' was specified "
                              "but no transformation for parallel execution was "
                              "possible.\n\nTo find out why, try turning on parallel "
                              "diagnostics, see %s for help." % url)
                       warnings.warn(errors.NumbaPerformanceWarning(msg,
                                                                    state.func_ir.loc))
       
               # Add reload function to initialize the parallel backend.
               state.reload_init.append(_reload_parfors)
               return True
       
       
    3: @register_pass(mutates_CFG=True, analysis_only=False)
    2: class ParforFusionPass(FunctionPass):
       
    1:     _name = "parfor_fusion_pass"
       
    1:     def __init__(self):
    1:         FunctionPass.__init__(self)
       
    1:     def run_pass(self, state):
               """
               Do fusion of parfor nodes.
               """
               # Ensure we have an IR and type information.
               assert state.func_ir
               parfor_pass = _parfor_ParforFusionPass(state.func_ir,
                                                      state.typemap,
                                                      state.calltypes,
                                                      state.return_type,
                                                      state.typingctx,
                                                      state.targetctx,
                                                      state.flags.auto_parallel,
                                                      state.flags,
                                                      state.metadata,
                                                      state.parfor_diagnostics)
               parfor_pass.run()
       
               return True
       
       
    3: @register_pass(mutates_CFG=True, analysis_only=False)
    2: class ParforPreLoweringPass(FunctionPass):
       
    1:     _name = "parfor_prelowering_pass"
       
    1:     def __init__(self):
    1:         FunctionPass.__init__(self)
       
    1:     def run_pass(self, state):
               """
               Prepare parfors for lowering.
               """
               # Ensure we have an IR and type information.
               assert state.func_ir
               parfor_pass = _parfor_ParforPreLoweringPass(state.func_ir,
                                                           state.typemap,
                                                           state.calltypes,
                                                           state.return_type,
                                                           state.typingctx,
                                                           state.targetctx,
                                                           state.flags.auto_parallel,
                                                           state.flags,
                                                           state.metadata,
                                                           state.parfor_diagnostics)
               parfor_pass.run()
       
               return True
       
       
    3: @register_pass(mutates_CFG=False, analysis_only=True)
    2: class DumpParforDiagnostics(AnalysisPass):
       
    1:     _name = "dump_parfor_diagnostics"
       
    1:     def __init__(self):
    1:         AnalysisPass.__init__(self)
       
    1:     def run_pass(self, state):
   24:         if state.flags.auto_parallel.enabled:
                   if config.PARALLEL_DIAGNOSTICS:
                       if state.parfor_diagnostics is not None:
                           state.parfor_diagnostics.dump(config.PARALLEL_DIAGNOSTICS)
                       else:
                           raise RuntimeError("Diagnostics failed.")
   24:         return True
       
       
    2: class BaseNativeLowering(abc.ABC, LoweringPass):
    1:     """The base class for a lowering pass. The lowering functionality must be
           specified in inheriting classes by providing an appropriate lowering class
           implementation in the overridden `lowering_class` property."""
       
    1:     _name = None
       
    1:     def __init__(self):
    2:         LoweringPass.__init__(self)
       
    2:     @property
    2:     @abc.abstractmethod
    2:     def lowering_class(self):
               """Returns the class that performs the lowering of the IR describing the
               function that is the target of the current compilation."""
               pass
       
    1:     def run_pass(self, state):
   24:         if state.library is None:
   17:             codegen = state.targetctx.codegen()
   17:             state.library = codegen.create_library(state.func_id.func_qualname)
                   # Enable object caching upfront, so that the library can
                   # be later serialized.
   17:             state.library.enable_object_caching()
       
   24:         library = state.library
   24:         targetctx = state.targetctx
   24:         interp = state.func_ir  # why is it called this?!
   24:         typemap = state.typemap
   24:         restype = state.return_type
   24:         calltypes = state.calltypes
   24:         flags = state.flags
   24:         metadata = state.metadata
   24:         pre_stats = llvm.passmanagers.dump_refprune_stats()
       
   24:         msg = ("Function %s failed at nopython "
   24:                "mode lowering" % (state.func_id.func_name,))
   48:         with fallback_context(state, msg):
                   # Lowering
   24:             fndesc = \
   48:                 funcdesc.PythonFunctionDescriptor.from_specialized_function(
   24:                     interp, typemap, restype, calltypes,
   24:                     mangler=targetctx.mangler, inline=flags.forceinline,
   24:                     noalias=flags.noalias, abi_tags=[flags.get_mangle_string()])
       
   48:             with targetctx.push_code_library(library):
   48:                 lower = self.lowering_class(targetctx, library, fndesc, interp,
   24:                                             metadata=metadata)
   24:                 lower.lower()
   24:                 if not flags.no_cpython_wrapper:
    2:                     lower.create_cpython_wrapper(flags.release_gil)
       
   24:                 if not flags.no_cfunc_wrapper:
                           # skip cfunc wrapper generation if unsupported
                           # argument or return types are used
   48:                     for t in state.args:
   37:                         if isinstance(t, (types.Omitted, types.Generator)):
    6:                             break
                           else:
   22:                         if isinstance(restype,
   11:                                       (types.Optional, types.Generator)):
                                   pass
                               else:
   11:                             lower.create_cfunc_wrapper()
       
   24:                 env = lower.env
   24:                 call_helper = lower.call_helper
   24:                 del lower
       
   24:             from numba.core.compiler import _LowerResult  # TODO: move this
   24:             if flags.no_compile:
   14:                 state['cr'] = _LowerResult(fndesc, call_helper,
    7:                                            cfunc=None, env=env)
                   else:
                       # Prepare for execution
                       # Insert native function for use by other jitted-functions.
                       # We also register its library to allow for inlining.
   17:                 cfunc = targetctx.get_executable(library, fndesc, env)
   17:                 targetctx.insert_user_function(cfunc, fndesc, [library])
   34:                 state['cr'] = _LowerResult(fndesc, call_helper,
   17:                                            cfunc=cfunc, env=env)
       
                   # capture pruning stats
   24:             post_stats = llvm.passmanagers.dump_refprune_stats()
   24:             metadata['prune_stats'] = post_stats - pre_stats
       
                   # Save the LLVM pass timings
   24:             metadata['llvm_pass_timings'] = library.recorded_timings
   24:         return True
       
       
    3: @register_pass(mutates_CFG=True, analysis_only=False)
    2: class NativeLowering(BaseNativeLowering):
    1:     """Lowering pass for a native function IR described solely in terms of
            Numba's standard `numba.core.ir` nodes."""
    1:     _name = "native_lowering"
       
    2:     @property
    2:     def lowering_class(self):
   24:         return lowering.Lower
       
       
    3: @register_pass(mutates_CFG=True, analysis_only=False)
    2: class NativeParforLowering(BaseNativeLowering):
    1:     """Lowering pass for a native function IR described using Numba's standard
           `numba.core.ir` nodes and also parfor.Parfor nodes."""
    1:     _name = "native_parfor_lowering"
       
    2:     @property
    2:     def lowering_class(self):
               return ParforLower
       
       
    3: @register_pass(mutates_CFG=False, analysis_only=True)
    2: class NoPythonSupportedFeatureValidation(AnalysisPass):
    1:     """NoPython Mode check: Validates the IR to ensure that features in use are
           in a form that is supported"""
       
    1:     _name = "nopython_supported_feature_validation"
       
    1:     def __init__(self):
    1:         AnalysisPass.__init__(self)
       
    1:     def run_pass(self, state):
   24:         raise_on_unsupported_feature(state.func_ir, state.typemap)
   24:         warn_deprecated(state.func_ir, state.typemap)
   24:         return False
       
       
    3: @register_pass(mutates_CFG=False, analysis_only=True)
    2: class IRLegalization(AnalysisPass):
       
    1:     _name = "ir_legalization"
       
    1:     def __init__(self):
    1:         AnalysisPass.__init__(self)
       
    1:     def run_pass(self, state):
               # NOTE: this function call must go last, it checks and fixes invalid IR!
   24:         check_and_legalize_ir(state.func_ir, flags=state.flags)
   24:         return True
       
       
    3: @register_pass(mutates_CFG=True, analysis_only=False)
    2: class NoPythonBackend(LoweringPass):
       
    1:     _name = "nopython_backend"
       
    1:     def __init__(self):
    1:         LoweringPass.__init__(self)
       
    1:     def run_pass(self, state):
               """
               Back-end: Generate LLVM IR from Numba IR, compile to machine code
               """
   24:         lowered = state['cr']
   24:         signature = typing.signature(state.return_type, *state.args)
       
   24:         from numba.core.compiler import compile_result
   48:         state.cr = compile_result(
   24:             typing_context=state.typingctx,
   24:             target_context=state.targetctx,
   24:             entry_point=lowered.cfunc,
   24:             typing_error=state.status.fail_reason,
   24:             type_annotation=state.type_annotation,
   24:             library=state.library,
   24:             call_helper=lowered.call_helper,
   24:             signature=signature,
   24:             objectmode=False,
   24:             lifted=state.lifted,
   24:             fndesc=lowered.fndesc,
   24:             environment=lowered.env,
   24:             metadata=state.metadata,
   24:             reload_init=state.reload_init,
               )
   24:         return True
       
       
    3: @register_pass(mutates_CFG=True, analysis_only=False)
    2: class InlineOverloads(FunctionPass):
    1:     """
           This pass will inline a function wrapped by the numba.extending.overload
           decorator directly into the site of its call depending on the value set in
           the 'inline' kwarg to the decorator.
       
           This is a typed pass. CFG simplification and DCE are performed on
           completion.
           """
       
    1:     _name = "inline_overloads"
       
    1:     def __init__(self):
    1:         FunctionPass.__init__(self)
       
    1:     _DEBUG = False
       
    1:     def run_pass(self, state):
               """Run inlining of overloads
               """
   24:         if self._DEBUG:
                   print('before overload inline'.center(80, '-'))
                   print(state.func_id.unique_name)
                   print(state.func_ir.dump())
                   print(''.center(80, '-'))
   24:         from numba.core.inline_closurecall import (InlineWorker,
                                                          callee_ir_validator)
   48:         inline_worker = InlineWorker(state.typingctx,
   24:                                      state.targetctx,
   24:                                      state.locals,
   24:                                      state.pipeline,
   24:                                      state.flags,
   24:                                      callee_ir_validator,
   24:                                      state.typemap,
   24:                                      state.calltypes,
                                            )
   24:         modified = False
   24:         work_list = list(state.func_ir.blocks.items())
               # use a work list, look for call sites via `ir.Expr.op == call` and
               # then pass these to `self._do_work` to make decisions about inlining.
  119:         while work_list:
   95:             label, block = work_list.pop()
  757:             for i, instr in enumerate(block.body):
                       # TO-DO: other statements (setitem)
  662:                 if isinstance(instr, ir.Assign):
  561:                     expr = instr.value
  561:                     if isinstance(expr, ir.Expr):
  296:                         workfn = self._do_work_expr
       
  592:                         if guard(workfn, state, work_list, block, i, expr,
  296:                                  inline_worker):
                                   modified = True
                                   break  # because block structure changed
       
   24:         if self._DEBUG:
                   print('after overload inline'.center(80, '-'))
                   print(state.func_id.unique_name)
                   print(state.func_ir.dump())
                   print(''.center(80, '-'))
       
   24:         if modified:
                   # Remove dead blocks, this is safe as it relies on the CFG only.
                   cfg = compute_cfg_from_blocks(state.func_ir.blocks)
                   for dead in cfg.dead_nodes():
                       del state.func_ir.blocks[dead]
                   # clean up blocks
                   dead_code_elimination(state.func_ir,
                                         typemap=state.typemap)
                   # clean up unconditional branches that appear due to inlined
                   # functions introducing blocks
                   state.func_ir.blocks = simplify_CFG(state.func_ir.blocks)
       
   24:         if self._DEBUG:
                   print('after overload inline DCE'.center(80, '-'))
                   print(state.func_id.unique_name)
                   print(state.func_ir.dump())
                   print(''.center(80, '-'))
   24:         return True
       
    1:     def _get_attr_info(self, state, expr):
   50:         recv_type = state.typemap[expr.value.name]
   50:         recv_type = types.unliteral(recv_type)
  100:         matched = state.typingctx.find_matching_getattr_template(
   50:             recv_type, expr.attr,
               )
   50:         if not matched:
   33:             return None
       
   17:         template = matched['template']
   17:         if getattr(template, 'is_method', False):
                   # The attribute template is representing a method.
                   # Don't inline the getattr.
    2:             return None
       
   15:         templates = [template]
   15:         sig = typing.signature(matched['return_type'], recv_type)
   15:         arg_typs = sig.args
   15:         is_method = False
       
   15:         return templates, sig, arg_typs, is_method
       
    1:     def _get_callable_info(self, state, expr):
       
  246:         def get_func_type(state, expr):
  246:             func_ty = None
  246:             if expr.op == 'call':
                       # check this is a known and typed function
   96:                 try:
   96:                     func_ty = state.typemap[expr.func.name]
                       except KeyError:
                           # e.g. Calls to CUDA Intrinsic have no mapped type
                           # so KeyError
                           return None
   96:                 if not hasattr(func_ty, 'get_call_type'):
                           return None
       
  150:             elif is_operator_or_getitem(expr):
   80:                 func_ty = state.typingctx.resolve_value_type(expr.fn)
                   else:
   70:                 return None
       
  176:             return func_ty
       
  246:         if expr.op == 'call':
                   # try and get a definition for the call, this isn't always
                   # possible as it might be a eval(str)/part generated
                   # awaiting update etc. (parfors)
   96:             to_inline = None
   96:             try:
   96:                 to_inline = state.func_ir.get_definition(expr.func)
                   except Exception:
                       return None
       
                   # do not handle closure inlining here, another pass deals with that
   96:             if getattr(to_inline, 'op', False) == 'make_function':
                       return None
       
  246:         func_ty = get_func_type(state, expr)
  246:         if func_ty is None:
   70:             return None
       
  176:         sig = state.calltypes[expr]
  176:         if not sig:
    6:             return None
       
  170:         templates, arg_typs, is_method = None, None, False
  170:         if getattr(func_ty, 'template', None) is not None:
                   # @overload_method
    2:             is_method = True
    2:             templates = [func_ty.template]
    2:             arg_typs = (func_ty.template.this,) + sig.args
               else:
                   # @overload case
  168:             templates = getattr(func_ty, 'templates', None)
  168:             arg_typs = sig.args
       
  170:         return templates, sig, arg_typs, is_method
       
    1:     def _do_work_expr(self, state, work_list, block, i, expr, inline_worker):
       
  296:         def select_template(templates, args):
  185:             if templates is None:
    3:                 return None
       
  182:             impl = None
 1063:             for template in templates:
  881:                 inline_type = getattr(template, '_inline', None)
  881:                 if inline_type is None:
                           # inline not defined
  432:                     continue
  449:                 if args not in template._inline_overloads:
                           # skip overloads not matching signature
  449:                     continue
                       if not inline_type.is_never_inline:
                           try:
                               impl = template._overload_func(*args)
                               if impl is None:
                                   raise Exception  # abort for this template
                               break
                           except Exception:
                               continue
                   else:
  182:                 return None
       
                   return template, inline_type, impl
       
  296:         inlinee_info = None
  296:         if expr.op == 'getattr':
   50:             inlinee_info = self._get_attr_info(state, expr)
               else:
  246:             inlinee_info = self._get_callable_info(state, expr)
       
  296:         if not inlinee_info:
  111:             return False
       
  185:         templates, sig, arg_typs, is_method = inlinee_info
  185:         inlinee = select_template(templates, arg_typs)
  185:         if inlinee is None:
  185:             return False
               template, inlinee_type, impl = inlinee
       
               return self._run_inliner(
                   state, inlinee_type, sig, template, arg_typs, expr, i, impl, block,
                   work_list, is_method, inline_worker,
               )
       
    1:     def _run_inliner(
               self, state, inline_type, sig, template, arg_typs, expr, i, impl, block,
               work_list, is_method, inline_worker,
           ):
       
               do_inline = True
               if not inline_type.is_always_inline:
                   from numba.core.typing.templates import _inline_info
                   caller_inline_info = _inline_info(state.func_ir,
                                                     state.typemap,
                                                     state.calltypes,
                                                     sig)
       
                   # must be a cost-model function, run the function
                   iinfo = template._inline_overloads[arg_typs]['iinfo']
                   if inline_type.has_cost_model:
                       do_inline = inline_type.value(expr, caller_inline_info, iinfo)
                   else:
                       assert 'unreachable'
       
               if do_inline:
                   if is_method:
                       if not self._add_method_self_arg(state, expr):
                           return False
                   arg_typs = template._inline_overloads[arg_typs]['folded_args']
                   iinfo = template._inline_overloads[arg_typs]['iinfo']
                   freevars = iinfo.func_ir.func_id.func.__code__.co_freevars
                   _, _, _, new_blocks = inline_worker.inline_ir(state.func_ir,
                                                                 block,
                                                                 i,
                                                                 iinfo.func_ir,
                                                                 freevars,
                                                                 arg_typs=arg_typs)
                   if work_list is not None:
                       for blk in new_blocks:
                           work_list.append(blk)
                   return True
               else:
                   return False
       
    1:     def _add_method_self_arg(self, state, expr):
               func_def = guard(get_definition, state.func_ir, expr.func)
               if func_def is None:
                   return False
               expr.args.insert(0, func_def.value)
               return True
       
       
    3: @register_pass(mutates_CFG=False, analysis_only=False)
    2: class DeadCodeElimination(FunctionPass):
    1:     """
           Does dead code elimination
           """
       
    1:     _name = "dead_code_elimination"
       
    1:     def __init__(self):
    1:         FunctionPass.__init__(self)
       
    1:     def run_pass(self, state):
               dead_code_elimination(state.func_ir, state.typemap)
               return True
       
       
    3: @register_pass(mutates_CFG=False, analysis_only=False)
    2: class PreLowerStripPhis(FunctionPass):
    1:     """Remove phi nodes (ir.Expr.phi) introduced by SSA.
       
           This is needed before Lowering because the phi nodes in Numba IR do not
           match the semantics of phi nodes in LLVM IR. In Numba IR, phi nodes may
           expand into multiple LLVM instructions.
           """
       
    1:     _name = "strip_phis"
       
    1:     def __init__(self):
    1:         FunctionPass.__init__(self)
       
    1:     def run_pass(self, state):
   24:         state.func_ir = self._strip_phi_nodes(state.func_ir)
   24:         state.func_ir._definitions = build_definitions(state.func_ir.blocks)
   24:         if "flags" in state and state.flags.auto_parallel.enabled:
                   self._simplify_conditionally_defined_variable(state.func_ir)
                   state.func_ir._definitions = build_definitions(state.func_ir.blocks)
       
               # Rerun postprocessor to update metadata
   24:         post_proc = postproc.PostProcessor(state.func_ir)
   24:         post_proc.run(emit_dels=False)
       
               # Ensure we are not in objectmode generator
   24:         if (state.func_ir.generator_info is not None
                       and state.typemap is not None):
                   # Rebuild generator type
                   # TODO: move this into PostProcessor
                   gentype = state.return_type
                   state_vars = state.func_ir.generator_info.state_vars
                   state_types = [state.typemap[k] for k in state_vars]
                   state.return_type = types.Generator(
                       gen_func=gentype.gen_func,
                       yield_type=gentype.yield_type,
                       arg_types=gentype.arg_types,
                       state_types=state_types,
                       has_finalizer=gentype.has_finalizer,
                   )
   24:         return True
       
    1:     def _strip_phi_nodes(self, func_ir):
               """Strip Phi nodes from ``func_ir``
       
               For each phi node, put incoming value to their respective incoming
               basic-block at possibly the latest position (i.e. after the latest
               assignment to the corresponding variable).
               """
   24:         exporters = defaultdict(list)
   24:         phis = set()
               # Find all variables that needs to be exported
  119:         for label, block in func_ir.blocks.items():
  639:             for assign in block.find_insts(ir.Assign):
  544:                 if isinstance(assign.value, ir.Expr):
  313:                     if assign.value.op == 'phi':
   17:                         phis.add(assign)
   17:                         phi = assign.value
   68:                         for ib, iv in zip(phi.incoming_blocks,
   17:                                           phi.incoming_values):
   34:                             exporters[ib].append((assign.target, iv))
       
               # Rewrite the blocks with the new exporting assignments
   24:         newblocks = {}
  119:         for label, block in func_ir.blocks.items():
   95:             newblk = copy(block)
   95:             newblocks[label] = newblk
       
                   # strip phis
  835:             newblk.body = [stmt for stmt in block.body if stmt not in phis]
       
                   # insert exporters
  129:             for target, rhs in exporters[label]:
                       # If RHS is undefined
   34:                 if rhs is ir.UNDEFINED:
                           # Put in a NULL initializer, set the location to be in what
                           # will eventually materialize as the prologue.
                           rhs = ir.Expr.null(loc=func_ir.loc)
       
   68:                 assign = ir.Assign(
   34:                     target=target,
   34:                     value=rhs,
   34:                     loc=rhs.loc
                       )
                       # Insert at the earliest possible location; i.e. after the
                       # last assignment to rhs
  347:                 assignments = [stmt for stmt in newblk.find_insts(ir.Assign)
  313:                                if stmt.target == rhs]
   34:                 if assignments:
   25:                     last_assignment = assignments[-1]
   25:                     newblk.insert_after(assign, last_assignment)
                       else:
    9:                     newblk.prepend(assign)
       
   24:         func_ir.blocks = newblocks
   24:         return func_ir
       
    1:     def _simplify_conditionally_defined_variable(self, func_ir):
               """
               Rewrite assignments like:
       
                   ver1 = null()
                   ...
                   ver1 = ver
                   ...
                   uses(ver1)
       
               into:
                   # delete all assignments to ver1
                   uses(ver)
       
               This is only needed for parfors because the SSA pass will create extra
               variable assignments that the parfor code does not expect.
               This pass helps avoid problems by reverting the effect of SSA.
               """
               any_block = next(iter(func_ir.blocks.values()))
               scope = any_block.scope
               defs = func_ir._definitions
       
               def unver_or_undef(unver, defn):
                   # Is the definition undefined or pointing to the unversioned name?
                   if isinstance(defn, ir.Var):
                       if defn.unversioned_name == unver:
                           return True
                   elif isinstance(defn, ir.Expr):
                       if defn.op == "null":
                           return True
                   return False
       
               def legalize_all_versioned_names(var):
                   # Are all versioned names undefined or defined to the same
                   # variable chain?
                   if not var.versioned_names:
                       return False
                   for versioned in var.versioned_names:
                       vs = defs.get(versioned, ())
                       if not all(map(partial(unver_or_undef, k), vs)):
                           return False
                   return True
       
               # Find unversioned variables that met the conditions
               suspects = set()
               for k in defs:
                   try:
                       # This may fail?
                       var = scope.get_exact(k)
                   except errors.NotDefinedError:
                       continue
                   # is the var name unversioned?
                   if var.unversioned_name == k:
                       if legalize_all_versioned_names(var):
                           suspects.add(var)
       
               delete_set = set()
               replace_map = {}
               for var in suspects:
                   # rewrite Var uses to the unversioned name
                   for versioned in var.versioned_names:
                       ver_var = scope.get_exact(versioned)
                       # delete assignment to the versioned name
                       delete_set.add(ver_var)
                       # replace references to versioned name with the unversioned
                       replace_map[versioned] = var
       
               # remove assignments to the versioned names
               for _label, blk in func_ir.blocks.items():
                   for assign in blk.find_insts(ir.Assign):
                       if assign.target in delete_set:
                           blk.remove(assign)
               # do variable replacement
               replace_vars(func_ir.blocks, replace_map)
