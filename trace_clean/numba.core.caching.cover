    1: """
       Caching mechanism for compiled functions.
       """
       
       
    1: from abc import ABCMeta, abstractmethod, abstractproperty
    1: import contextlib
    1: import errno
    1: import hashlib
    1: import inspect
    1: import itertools
    1: import os
    1: import pickle
    1: import sys
    1: import tempfile
    1: import uuid
    1: import warnings
       
    1: from numba.misc.appdirs import AppDirs
       
    1: import numba
    1: from numba.core.errors import NumbaWarning
    1: from numba.core.base import BaseContext
    1: from numba.core.codegen import CodeLibrary
    1: from numba.core.compiler import CompileResult
    1: from numba.core import config, compiler
    1: from numba.core.serialize import dumps
       
       
    1: def _cache_log(msg, *args):
    6:     if config.DEBUG_CACHE:
               msg = msg % args
               print(msg)
       
       
    2: class _Cache(metaclass=ABCMeta):
       
    2:     @abstractproperty
    2:     def cache_path(self):
               """
               The base filesystem path of this cache (for example its root folder).
               """
       
    2:     @abstractmethod
    2:     def load_overload(self, sig, target_context):
               """
               Load an overload for the given signature using the target context.
               The saved object must be returned if successful, None if not found
               in the cache.
               """
       
    2:     @abstractmethod
    2:     def save_overload(self, sig, data):
               """
               Save the overload for the given signature.
               """
       
    2:     @abstractmethod
    2:     def enable(self):
               """
               Enable the cache.
               """
       
    2:     @abstractmethod
    2:     def disable(self):
               """
               Disable the cache.
               """
       
    2:     @abstractmethod
    2:     def flush(self):
               """
               Flush the cache.
               """
       
       
    2: class NullCache(_Cache):
    2:     @property
    2:     def cache_path(self):
               return None
       
    1:     def load_overload(self, sig, target_context):
   17:         pass
       
    1:     def save_overload(self, sig, cres):
   17:         pass
       
    1:     def enable(self):
               pass
       
    1:     def disable(self):
               pass
       
    1:     def flush(self):
               pass
       
       
    2: class _CacheLocator(metaclass=ABCMeta):
    1:     """
           A filesystem locator for caching a given function.
           """
       
    1:     def ensure_cache_path(self):
    4:         path = self.get_cache_path()
    4:         os.makedirs(path, exist_ok=True)
               # Ensure the directory is writable by trying to write a temporary file
    4:         tempfile.TemporaryFile(dir=path).close()
       
    2:     @abstractmethod
    2:     def get_cache_path(self):
               """
               Return the directory the function is cached in.
               """
       
    2:     @abstractmethod
    2:     def get_source_stamp(self):
               """
               Get a timestamp representing the source code's freshness.
               Can return any picklable Python object.
               """
       
    2:     @abstractmethod
    2:     def get_disambiguator(self):
               """
               Get a string disambiguator for this locator's function.
               It should allow disambiguating different but similarly-named functions.
               """
       
    2:     @classmethod
    2:     def from_function(cls, py_func, py_file):
               """
               Create a locator instance for the given function located in the
               given file.
               """
               raise NotImplementedError
       
    2:     @classmethod
    2:     def get_suitable_cache_subpath(cls, py_file):
               """Given the Python file path, compute a suitable path inside the
               cache directory.
       
               This will reduce a file path that is too long, which can be a problem
               on some operating system (i.e. Windows 7).
               """
               path = os.path.abspath(py_file)
               subpath = os.path.dirname(path)
               parentdir = os.path.split(subpath)[-1]
               # Use SHA1 to reduce path length.
               # Note: windows doesn't like long path.
               hashed = hashlib.sha1(subpath.encode()).hexdigest()
               # Retain parent directory name for easier debugging
               return '_'.join([parentdir, hashed])
       
       
    2: class _SourceFileBackedLocatorMixin(object):
    1:     """
           A cache locator mixin for functions which are backed by a well-known
           Python source file.
           """
       
    1:     def get_source_stamp(self):
    4:         if getattr(sys, 'frozen', False):
                   st = os.stat(sys.executable)
               else:
    4:             st = os.stat(self._py_file)
               # We use both timestamp and size as some filesystems only have second
               # granularity.
    4:         return st.st_mtime, st.st_size
       
    1:     def get_disambiguator(self):
    4:         return str(self._lineno)
       
    2:     @classmethod
    2:     def from_function(cls, py_func, py_file):
    4:         if not os.path.exists(py_file):
                   # Perhaps a placeholder (e.g. "<ipython-XXX>")
                   return
    4:         self = cls(py_func, py_file)
    4:         try:
    4:             self.ensure_cache_path()
               except OSError:
                   # Cannot ensure the cache directory exists or is writable
                   return
    4:         return self
       
       
    2: class _UserProvidedCacheLocator(_SourceFileBackedLocatorMixin, _CacheLocator):
    1:     """
           A locator that always point to the user provided directory in
           `numba.config.CACHE_DIR`
           """
    1:     def __init__(self, py_func, py_file):
               self._py_file = py_file
               self._lineno = py_func.__code__.co_firstlineno
               cache_subpath = self.get_suitable_cache_subpath(py_file)
               self._cache_path = os.path.join(config.CACHE_DIR, cache_subpath)
       
    1:     def get_cache_path(self):
               return self._cache_path
       
    2:     @classmethod
    2:     def from_function(cls, py_func, py_file):
    4:         if not config.CACHE_DIR:
    4:             return
               parent = super(_UserProvidedCacheLocator, cls)
               return parent.from_function(py_func, py_file)
       
       
    2: class _InTreeCacheLocator(_SourceFileBackedLocatorMixin, _CacheLocator):
    1:     """
           A locator for functions backed by a regular Python module with a
           writable __pycache__ directory.
           """
       
    1:     def __init__(self, py_func, py_file):
    4:         self._py_file = py_file
    4:         self._lineno = py_func.__code__.co_firstlineno
    4:         self._cache_path = os.path.join(os.path.dirname(self._py_file), '__pycache__')
       
    1:     def get_cache_path(self):
    8:         return self._cache_path
       
       
    2: class _UserWideCacheLocator(_SourceFileBackedLocatorMixin, _CacheLocator):
    1:     """
           A locator for functions backed by a regular Python module or a
           frozen executable, cached into a user-wide cache directory.
           """
       
    1:     def __init__(self, py_func, py_file):
               self._py_file = py_file
               self._lineno = py_func.__code__.co_firstlineno
               appdirs = AppDirs(appname="numba", appauthor=False)
               cache_dir = appdirs.user_cache_dir
               cache_subpath = self.get_suitable_cache_subpath(py_file)
               self._cache_path = os.path.join(cache_dir, cache_subpath)
       
    1:     def get_cache_path(self):
               return self._cache_path
       
    2:     @classmethod
    2:     def from_function(cls, py_func, py_file):
               if not (os.path.exists(py_file) or getattr(sys, 'frozen', False)):
                   # Perhaps a placeholder (e.g. "<ipython-XXX>")
                   # stop function exit if frozen, since it uses a temp placeholder
                   return
               self = cls(py_func, py_file)
               try:
                   self.ensure_cache_path()
               except OSError:
                   # Cannot ensure the cache directory exists or is writable
                   return
               return self
       
       
    2: class _IPythonCacheLocator(_CacheLocator):
    1:     """
           A locator for functions entered at the IPython prompt (notebook or other).
           """
       
    1:     def __init__(self, py_func, py_file):
               self._py_file = py_file
               # Note IPython enhances the linecache module to be able to
               # inspect source code of functions defined on the interactive prompt.
               source = inspect.getsource(py_func)
               if isinstance(source, bytes):
                   self._bytes_source = source
               else:
                   self._bytes_source = source.encode('utf-8')
       
    1:     def get_cache_path(self):
               # We could also use jupyter_core.paths.jupyter_runtime_dir()
               # In both cases this is a user-wide directory, so we need to
               # be careful when disambiguating if we don't want too many
               # conflicts (see below).
               try:
                   from IPython.paths import get_ipython_cache_dir
               except ImportError:
                   # older IPython version
                   from IPython.utils.path import get_ipython_cache_dir
               return os.path.join(get_ipython_cache_dir(), 'numba_cache')
       
    1:     def get_source_stamp(self):
               return hashlib.sha256(self._bytes_source).hexdigest()
       
    1:     def get_disambiguator(self):
               # Heuristic: we don't want too many variants being saved, but
               # we don't want similar named functions (e.g. "f") to compete
               # for the cache, so we hash the first two lines of the function
               # source (usually this will be the @jit decorator + the function
               # signature).
               firstlines = b''.join(self._bytes_source.splitlines(True)[:2])
               return hashlib.sha256(firstlines).hexdigest()[:10]
       
    2:     @classmethod
    2:     def from_function(cls, py_func, py_file):
               if not (
                   py_file.startswith("<ipython-")
                   or os.path.basename(os.path.dirname(py_file)).startswith("ipykernel_")
               ):
                   return
               self = cls(py_func, py_file)
               try:
                   self.ensure_cache_path()
               except OSError:
                   # Cannot ensure the cache directory exists
                   return
               return self
       
       
    2: class CacheImpl(metaclass=ABCMeta):
    1:     """
           Provides the core machinery for caching.
           - implement how to serialize and deserialize the data in the cache.
           - control the filename of the cache.
           - provide the cache locator
           """
    2:     _locator_classes = [_UserProvidedCacheLocator,
    1:                         _InTreeCacheLocator,
    1:                         _UserWideCacheLocator,
    1:                         _IPythonCacheLocator]
       
    1:     def __init__(self, py_func):
    4:         self._lineno = py_func.__code__.co_firstlineno
               # Get qualname
    4:         try:
    4:             qualname = py_func.__qualname__
               except AttributeError:
                   qualname = py_func.__name__
               # Find a locator
    4:         source_path = inspect.getfile(py_func)
    8:         for cls in self._locator_classes:
    8:             locator = cls.from_function(py_func, source_path)
    8:             if locator is not None:
    4:                 break
               else:
                   raise RuntimeError("cannot cache function %r: no locator available "
                                      "for file %r" % (qualname, source_path))
    4:         self._locator = locator
               # Use filename base name as module name to avoid conflict between
               # foo/__init__.py and foo/foo.py
    4:         filename = inspect.getfile(py_func)
    4:         modname = os.path.splitext(os.path.basename(filename))[0]
    4:         fullname = "%s.%s" % (modname, qualname)
    4:         abiflags = getattr(sys, 'abiflags', '')
    4:         self._filename_base = self.get_filename_base(fullname, abiflags)
       
    1:     def get_filename_base(self, fullname, abiflags):
               # '<' and '>' can appear in the qualname (e.g. '<locals>') but
               # are forbidden in Windows filenames
    4:         fixed_fullname = fullname.replace('<', '').replace('>', '')
    4:         fmt = '%s-%s.py%d%d%s'
    8:         return fmt % (fixed_fullname, self.locator.get_disambiguator(),
    4:                       sys.version_info[0], sys.version_info[1], abiflags)
       
    2:     @property
    2:     def filename_base(self):
    4:         return self._filename_base
       
    2:     @property
    2:     def locator(self):
   12:         return self._locator
       
    2:     @abstractmethod
    2:     def reduce(self, data):
               "Returns the serialized form the data"
               pass
       
    2:     @abstractmethod
    2:     def rebuild(self, target_context, reduced_data):
               "Returns the de-serialized form of the *reduced_data*"
               pass
       
    2:     @abstractmethod
    2:     def check_cachable(self, data):
               "Returns True if the given data is cachable; otherwise, returns False."
               pass
       
       
    2: class CompileResultCacheImpl(CacheImpl):
    1:     """
           Implements the logic to cache CompileResult objects.
           """
       
    1:     def reduce(self, cres):
               """
               Returns a serialized CompileResult
               """
               return cres._reduce()
       
    1:     def rebuild(self, target_context, payload):
               """
               Returns the unserialized CompileResult
               """
    3:         return compiler.CompileResult._rebuild(target_context, *payload)
       
    1:     def check_cachable(self, cres):
               """
               Check cachability of the given compile result.
               """
               cannot_cache = None
               if any(not x.can_cache for x in cres.lifted):
                   cannot_cache = "as it uses lifted code"
               elif cres.library.has_dynamic_globals:
                   cannot_cache = ("as it uses dynamic globals "
                                   "(such as ctypes pointers and large global arrays)")
               if cannot_cache:
                   msg = ('Cannot cache compiled function "%s" %s'
                          % (cres.fndesc.qualname.split('.')[-1], cannot_cache))
                   warnings.warn_explicit(msg, NumbaWarning,
                                          self._locator._py_file, self._lineno)
                   return False
               return True
       
       
    2: class CodeLibraryCacheImpl(CacheImpl):
    1:     """
           Implements the logic to cache CodeLibrary objects.
           """
       
    1:     _filename_prefix = None  # must be overridden
       
    1:     def reduce(self, codelib):
               """
               Returns a serialized CodeLibrary
               """
               return codelib.serialize_using_object_code()
       
    1:     def rebuild(self, target_context, payload):
               """
               Returns the unserialized CodeLibrary
               """
               return target_context.codegen().unserialize_library(payload)
       
    1:     def check_cachable(self, codelib):
               """
               Check cachability of the given CodeLibrary.
               """
               return not codelib.has_dynamic_globals
       
    1:     def get_filename_base(self, fullname, abiflags):
               parent = super(CodeLibraryCacheImpl, self)
               res = parent.get_filename_base(fullname, abiflags)
               return '-'.join([self._filename_prefix, res])
       
       
    2: class IndexDataCacheFile(object):
    1:     """
           Implements the logic for the index file and data file used by a cache.
           """
    1:     def __init__(self, cache_path, filename_base, source_stamp):
    4:         self._cache_path = cache_path
    4:         self._index_name = '%s.nbi' % (filename_base,)
    4:         self._index_path = os.path.join(self._cache_path, self._index_name)
    4:         self._data_name_pattern = '%s.{number:d}.nbc' % (filename_base,)
    4:         self._source_stamp = source_stamp
    4:         self._version = numba.__version__
       
    1:     def flush(self):
               self._save_index({})
       
    1:     def save(self, key, data):
               """
               Save a new cache entry with *key* and *data*.
               """
               overloads = self._load_index()
               try:
                   # If key already exists, we will overwrite the file
                   data_name = overloads[key]
               except KeyError:
                   # Find an available name for the data file
                   existing = set(overloads.values())
                   for i in itertools.count(1):
                       data_name = self._data_name(i)
                       if data_name not in existing:
                           break
                   overloads[key] = data_name
                   self._save_index(overloads)
               self._save_data(data_name, data)
       
    1:     def load(self, key):
               """
               Load a cache entry with *key*.
               """
    3:         overloads = self._load_index()
    3:         data_name = overloads.get(key)
    3:         if data_name is None:
                   return
    3:         try:
    3:             return self._load_data(data_name)
               except OSError:
                   # File could have been removed while the index still refers it.
                   return
       
    1:     def _load_index(self):
               """
               Load the cache index and return it as a dictionary (possibly
               empty if cache is empty or obsolete).
               """
    3:         try:
    6:             with open(self._index_path, "rb") as f:
    3:                 version = pickle.load(f)
    3:                 data = f.read()
               except FileNotFoundError:
                   # Index doesn't exist yet?
                   return {}
    3:         if version != self._version:
                   # This is another version.  Avoid trying to unpickling the
                   # rest of the stream, as that may fail.
                   return {}
    3:         stamp, overloads = pickle.loads(data)
    3:         _cache_log("[cache] index loaded from %r", self._index_path)
    3:         if stamp != self._source_stamp:
                   # Cache is not fresh.  Stale data files will be eventually
                   # overwritten, since they are numbered in incrementing order.
                   return {}
               else:
    3:             return overloads
       
    1:     def _save_index(self, overloads):
               data = self._source_stamp, overloads
               data = self._dump(data)
               with self._open_for_write(self._index_path) as f:
                   pickle.dump(self._version, f, protocol=-1)
                   f.write(data)
               _cache_log("[cache] index saved to %r", self._index_path)
       
    1:     def _load_data(self, name):
    3:         path = self._data_path(name)
    6:         with open(path, "rb") as f:
    3:             data = f.read()
    3:         tup = pickle.loads(data)
    3:         _cache_log("[cache] data loaded from %r", path)
    3:         return tup
       
    1:     def _save_data(self, name, data):
               data = self._dump(data)
               path = self._data_path(name)
               with self._open_for_write(path) as f:
                   f.write(data)
               _cache_log("[cache] data saved to %r", path)
       
    1:     def _data_name(self, number):
               return self._data_name_pattern.format(number=number)
       
    1:     def _data_path(self, name):
    3:         return os.path.join(self._cache_path, name)
       
    1:     def _dump(self, obj):
               return dumps(obj)
       
    2:     @contextlib.contextmanager
    2:     def _open_for_write(self, filepath):
               """
               Open *filepath* for writing in a race condition-free way (hopefully).
               uuid4 is used to try and avoid name collisions on a shared filesystem.
               """
               uid = uuid.uuid4().hex[:16]  # avoid long paths
               tmpname = '%s.tmp.%s' % (filepath, uid)
               try:
                   with open(tmpname, "wb") as f:
                       yield f
                   os.replace(tmpname, filepath)
               except Exception:
                   # In case of error, remove dangling tmp file
                   try:
                       os.unlink(tmpname)
                   except OSError:
                       pass
                   raise
       
       
    2: class Cache(_Cache):
    1:     """
           A per-function compilation cache.  The cache saves data in separate
           data files and maintains information in an index file.
       
           There is one index file per function and Python version
           ("function_name-<lineno>.pyXY.nbi") which contains a mapping of
           signatures and architectures to data files.
           It is prefixed by a versioning key and a timestamp of the Python source
           file containing the function.
       
           There is one data file ("function_name-<lineno>.pyXY.<number>.nbc")
           per function, function signature, target architecture and Python version.
       
           Separate index and data files per Python version avoid pickle
           compatibility problems.
       
           Note:
           This contains the driver logic only.  The core logic is provided
           by a subclass of ``CacheImpl`` specified as *_impl_class* in the subclass.
           """
       
           # The following class variables must be overridden by subclass.
    1:     _impl_class = None
       
    1:     def __init__(self, py_func):
    4:         self._name = repr(py_func)
    4:         self._py_func = py_func
    4:         self._impl = self._impl_class(py_func)
    4:         self._cache_path = self._impl.locator.get_cache_path()
               # This may be a bit strict but avoids us maintaining a magic number
    4:         source_stamp = self._impl.locator.get_source_stamp()
    4:         filename_base = self._impl.filename_base
    8:         self._cache_file = IndexDataCacheFile(cache_path=self._cache_path,
    4:                                               filename_base=filename_base,
    4:                                               source_stamp=source_stamp)
    4:         self.enable()
       
    1:     def __repr__(self):
               return "<%s py_func=%r>" % (self.__class__.__name__, self._name)
       
    2:     @property
    2:     def cache_path(self):
               return self._cache_path
       
    1:     def enable(self):
    4:         self._enabled = True
       
    1:     def disable(self):
               self._enabled = False
       
    1:     def flush(self):
               self._cache_file.flush()
       
    1:     def load_overload(self, sig, target_context):
               """
               Load and recreate the cached object for the given signature,
               using the *target_context*.
               """
               # Refresh the context to ensure it is initialized
    3:         target_context.refresh()
    6:         with self._guard_against_spurious_io_errors():
    3:             return self._load_overload(sig, target_context)
               # None returned if the `with` block swallows an exception
       
    1:     def _load_overload(self, sig, target_context):
    3:         if not self._enabled:
                   return
    3:         key = self._index_key(sig, target_context.codegen())
    3:         data = self._cache_file.load(key)
    3:         if data is not None:
    3:             data = self._impl.rebuild(target_context, data)
    3:         return data
       
    1:     def save_overload(self, sig, data):
               """
               Save the data for the given signature in the cache.
               """
               with self._guard_against_spurious_io_errors():
                   self._save_overload(sig, data)
       
    1:     def _save_overload(self, sig, data):
               if not self._enabled:
                   return
               if not self._impl.check_cachable(data):
                   return
               self._impl.locator.ensure_cache_path()
               key = self._index_key(sig, data.codegen)
               data = self._impl.reduce(data)
               self._cache_file.save(key, data)
       
    2:     @contextlib.contextmanager
    2:     def _guard_against_spurious_io_errors(self):
    3:         if os.name == 'nt':
                   # Guard against permission errors due to accessing the file
                   # from several processes (see #2028)
                   try:
                       yield
                   except OSError as e:
                       if e.errno != errno.EACCES:
                           raise
               else:
                   # No such conditions under non-Windows OSes
    3:             yield
       
    1:     def _index_key(self, sig, codegen):
               """
               Compute index key for the given signature and codegen.
               It includes a description of the OS, target architecture and hashes of
               the bytecode for the function and, if the function has a __closure__,
               a hash of the cell_contents.
               """
    3:         codebytes = self._py_func.__code__.co_code
    3:         if self._py_func.__closure__ is not None:
                   cvars = tuple([x.cell_contents for x in self._py_func.__closure__])
                   # Note: cloudpickle serializes a function differently depending
                   #       on how the process is launched; e.g. multiprocessing.Process
                   cvarbytes = dumps(cvars)
               else:
    3:             cvarbytes = b''
       
    9:         hasher = lambda x: hashlib.sha256(x).hexdigest()
    6:         return (sig, codegen.magic_tuple(), (hasher(codebytes),
    3:                                              hasher(cvarbytes),))
       
       
    2: class FunctionCache(Cache):
    1:     """
           Implements Cache that saves and loads CompileResult objects.
           """
    1:     _impl_class = CompileResultCacheImpl
       
       
       # Remember used cache filename prefixes.
    1: _lib_cache_prefixes = set([''])
       
       
    1: def make_library_cache(prefix):
           """
           Create a Cache class for additional compilation features to cache their
           result for reuse.  The cache is saved in filename pattern like
           in ``FunctionCache`` but with additional *prefix* as specified.
           """
           # avoid cache prefix reuse
    1:     assert prefix not in _lib_cache_prefixes
    1:     _lib_cache_prefixes.add(prefix)
       
    2:     class CustomCodeLibraryCacheImpl(CodeLibraryCacheImpl):
    1:         _filename_prefix = prefix
       
    2:     class LibraryCache(Cache):
    1:         """
               Implements Cache that saves and loads CodeLibrary objects for additional
               feature for the specified python function.
               """
    1:         _impl_class = CustomCodeLibraryCacheImpl
       
    1:     return LibraryCache
       
